<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/apps/recommendation_agent/services/job_service.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/apps/recommendation_agent/services/job_service.py" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;Job Indexing Service for syncing jobs to Weaviate&#10;&quot;&quot;&quot;&#10;import logging&#10;&#10;logger = logging.getLogger(__name__)&#10;&#10;&#10;class JobIndexingService:&#10;    &quot;&quot;&quot;Service for indexing jobs to Weaviate&quot;&quot;&quot;&#10;    &#10;    @staticmethod&#10;    def sync_single_job_to_weaviate(job_id):&#10;        &quot;&quot;&quot;&#10;        Sync a single job to Weaviate&#10;        &#10;        Args:&#10;            job_id: ID of the job to sync&#10;            &#10;        Returns:&#10;            bool: True if successful, False otherwise&#10;        &quot;&quot;&quot;&#10;        try:&#10;            from ..models import JobPostings, JobDescription&#10;            from .weaviate_service import index_job, delete_job&#10;            &#10;            # Get job from database&#10;            try:&#10;                job = JobPostings.objects.select_related('recruiter').prefetch_related(&#10;                    'jobdescription_set__jd_skill'&#10;                ).get(id=job_id)&#10;            except JobPostings.DoesNotExist:&#10;                logger.warning(f&quot;Job {job_id} not found in database&quot;)&#10;                return False&#10;            &#10;            # If job is not active, remove from Weaviate&#10;            if job.status != 'ACTIVE':&#10;                return delete_job(job_id)&#10;            &#10;            # Prepare job data for indexing&#10;            skills = [jd.jd_skill.name for jd in job.jobdescription_set.all()]&#10;            &#10;            job_data = {&#10;                'job_id': job.id,&#10;                'title': job.title,&#10;                'description': job.description or '',&#10;                'skills': skills,&#10;                'company_name': job.recruiter.company_name,&#10;                'address': job.address or '',&#10;            }&#10;            &#10;            # Index to Weaviate&#10;            return index_job(job_data)&#10;            &#10;        except Exception as e:&#10;            logger.error(f&quot;Error syncing job {job_id} to Weaviate: {str(e)}&quot;)&#10;            return False&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/apps/recommendation_agent/services/recommendation_system.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/apps/recommendation_agent/services/recommendation_system.py" />
              <option name="originalContent" value="import asyncio&#10;&#10;import joblib&#10;import numpy as np&#10;import pandas as pd&#10;import os&#10;import django&#10;import sys&#10;from sqlalchemy import create_engine&#10;from asgiref.sync import sync_to_async&#10;&#10;from dotenv import load_dotenv&#10;from google import genai&#10;from surprise import Reader, Dataset, SVD, accuracy&#10;from surprise.model_selection import train_test_split&#10;&#10;from apps.recommendation_agent.services.weaviate_service import query_weaviate_async, manager&#10;from apps.recommendation_agent.services.overlap_skill import calculate_skill_overlap&#10;&#10;load_dotenv()&#10;MODEL_PATH = &quot;cf_model.pkl&quot;&#10;&#10;# Setup Django environment FIRST before importing models&#10;django_base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))&#10;sys.path.append(django_base_dir)&#10;os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'Careermate.settings')&#10;django.setup()&#10;&#10;# NOW import Django models after setup&#10;from django.conf import settings&#10;from apps.recommendation_agent.models import Candidate, JobPostings&#10;&#10;# Create SQLAlchemy engine from Django database settings&#10;def get_sqlalchemy_engine():&#10;    &quot;&quot;&quot;Create SQLAlchemy engine from Django database settings&quot;&quot;&quot;&#10;    db_settings = settings.DATABASES['default']&#10;    engine = db_settings.get('ENGINE', '')&#10;&#10;    if 'postgresql' in engine:&#10;        db_url = f&quot;postgresql://{db_settings['USER']}:{db_settings['PASSWORD']}@{db_settings['HOST']}:{db_settings.get('PORT', 5432)}/{db_settings['NAME']}&quot;&#10;    elif 'mysql' in engine:&#10;        db_url = f&quot;mysql+pymysql://{db_settings['USER']}:{db_settings['PASSWORD']}@{db_settings['HOST']}:{db_settings.get('PORT', 3306)}/{db_settings['NAME']}&quot;&#10;    else:&#10;        # SQLite or other&#10;        db_url = f&quot;sqlite:///{db_settings['NAME']}&quot;&#10;&#10;    return create_engine(db_url)&#10;&#10;# Get the correct path to the CSV file&#10;csv_path = os.path.join(settings.BASE_DIR, 'agent_core', 'data', 'job_postings.csv')&#10;data_jp = pd.read_csv(csv_path, encoding='latin-1')&#10;&#10;#get data from postgres by candidateId&#10;def get_candidate_by_id(candidate_id: int, resume_id: int | None = None) -&gt; dict | None:&#10;    &quot;&quot;&quot;&#10;    Get candidate by ID with their title and skills from resume(s).&#10;&#10;    Args:&#10;        candidate_id: The ID of the candidate&#10;        resume_id: Optional - If provided, only return this specific resume. If None, return all resumes.&#10;&#10;    Returns:&#10;        Dictionary with candidate title and skills from specified resume(s), or None if not found&#10;    &quot;&quot;&quot;&#10;    try:&#10;        candidate = (&#10;            Candidate.objects&#10;            .select_related('account')&#10;            .prefetch_related('resumes__skills')&#10;            .get(candidate_id=candidate_id)&#10;        )&#10;&#10;        resumes_data = []&#10;        # The 'resumes' relationship exists via Resume model's related_name='resumes'&#10;        # IDE may show warning because Candidate has managed=False, but it works at runtime&#10;        all_resumes = candidate.resumes.all().order_by('-created_at')  # type: ignore&#10;&#10;        # If resume_id is provided, filter to get only that specific resume&#10;        if resume_id is not None:&#10;            all_resumes = all_resumes.filter(resume_id=resume_id)&#10;            if not all_resumes.exists():&#10;                return None  # Resume not found for this candidate&#10;&#10;        for resume in all_resumes:&#10;            skills = []&#10;            for skill in resume.skills.all():&#10;                skills.append({&#10;                    &quot;skill_id&quot;: skill.skill_id,&#10;                    &quot;skill_name&quot;: skill.skill_name,&#10;                    &quot;yearOfExperience&quot;: skill.year_of_experience or 0&#10;                })&#10;&#10;            resumes_data.append({&#10;                &quot;title&quot;: candidate.title or &quot;&quot;,&#10;                &quot;resume_id&quot;: resume.resume_id,&#10;                &quot;skills&quot;: skills,&#10;                &quot;skills_count&quot;: len(skills)&#10;            })&#10;&#10;        return {&#10;            &quot;candidate_id&quot;: candidate.candidate_id,&#10;            &quot;title&quot;: candidate.title or &quot;&quot;,&#10;            &quot;resumes&quot;: resumes_data,&#10;        }&#10;    except Candidate.DoesNotExist:&#10;        return None&#10;&#10;#init weaviate&#10;# Initialize Gemini client&#10;gemini_client = genai.Client(api_key=os.getenv(&quot;GOOGLE_API_KEY&quot;))&#10;&#10;def get_gemini_embedding(text: str):&#10;    &quot;&quot;&quot;Tạo vector embedding bằng Gemini (models/embedding-001)&quot;&quot;&quot;&#10;    text = (text or &quot;&quot;).strip()&#10;    if not text:&#10;        return None&#10;&#10;    response = gemini_client.models.embed_content(&#10;        model=&quot;models/embedding-001&quot;,&#10;        contents=text&#10;    )&#10;&#10;    # Trả về list[float] (Weaviate yêu cầu dạng này)&#10;    return np.array(response.embeddings[0].values, dtype=np.float32).tolist()&#10;&#10;&#10;#Content-Based Recommendation with Skill Overlap Weighting&#10;async def get_content_based_recommendations(query_item, top_n=5, weights=None, skill_weight=0.4):&#10;    if weights is None:&#10;        weights = {&quot;skills&quot;: 0.5, &quot;title&quot;: 0.3, &quot;description&quot;: 0.15}&#10;&#10;    # 1️⃣ Combine all fields into weighted text&#10;    def to_text(v):&#10;        if isinstance(v, list):&#10;            return &quot;, &quot;.join(str(x) for x in v)&#10;        return str(v or &quot;&quot;)&#10;&#10;    # Create weighted combined text (repeat important fields to increase their weight)&#10;    skills_text = to_text(query_item.get(&quot;skills&quot;, &quot;&quot;))&#10;    title_text = to_text(query_item.get(&quot;title&quot;, &quot;&quot;))&#10;    description_text = to_text(query_item.get(&quot;description&quot;, &quot;&quot;))&#10;&#10;    # Combine with weights by repeating (simple but effective approach)&#10;    combined_parts = []&#10;    if skills_text:&#10;        combined_parts.extend([skills_text] * int(weights.get(&quot;skills&quot;, 0.5) * 10))  # High weight for skills&#10;    if title_text:&#10;        combined_parts.extend([title_text] * int(weights.get(&quot;title&quot;, 0.3) * 10))  # Medium weight for title&#10;    if description_text:&#10;        combined_parts.extend([description_text] * int(weights.get(&quot;description&quot;, 0.15) * 10))&#10;&#10;    combined_text = &quot; &quot;.join(combined_parts)&#10;&#10;    # 2️⃣ Create single embedding&#10;    # embedding = model.encode(combined_text, normalize_embeddings=True)&#10;    # vector = embedding.tolist()&#10;    vector = get_gemini_embedding(combined_text)&#10;    # 3️⃣ Query Weaviate with single vector (get more results for better filtering)&#10;    results = await query_weaviate_async(vector, limit=top_n * 3)  # Get 3x more for skill filtering&#10;&#10;    # 4️⃣ Calculate hybrid scores combining semantic similarity + skill overlap&#10;    query_skills = query_item.get(&quot;skills&quot;, [])&#10;    if isinstance(query_skills, str):&#10;        query_skills = [s.strip() for s in query_skills.split(&quot;,&quot;)]&#10;&#10;    formatted_results = []&#10;    for job in results:&#10;        # Parse job skills&#10;        job_skills_text = job[&quot;skills&quot;]&#10;        if isinstance(job_skills_text, str):&#10;            job_skills = [s.strip() for s in job_skills_text.split(&quot;,&quot;) if s.strip()]&#10;        else:&#10;            job_skills = []&#10;&#10;        # Calculate semantic similarity (from vector distance)&#10;        semantic_similarity = 1 - job[&quot;distance&quot;]&#10;&#10;        # Calculate skill overlap score&#10;        skill_overlap_score = calculate_skill_overlap(query_skills, job_skills)&#10;&#10;        # Hybrid score: weighted combination&#10;        hybrid_score = (1 - skill_weight) * semantic_similarity + skill_weight * skill_overlap_score&#10;&#10;        formatted_results.append({&#10;            &quot;job_id&quot;: job[&quot;job_id&quot;],&#10;            &quot;title&quot;: job[&quot;title&quot;],&#10;            &quot;skills&quot;: job[&quot;skills&quot;],&#10;            &quot;description&quot;: job.get(&quot;description&quot;, &quot;&quot;),&#10;            &quot;semantic_similarity&quot;: semantic_similarity,&#10;            &quot;similarity&quot;: hybrid_score  # For backward compatibility&#10;        })&#10;&#10;    # 5️⃣ Sort by hybrid score and return top N&#10;    formatted_results.sort(key=lambda x: x[&quot;similarity&quot;], reverse=True)&#10;&#10;    return formatted_results[:top_n]&#10;&#10;&#10;#Collaborative Filtering Recommendation can be added here similarly&#10;def _collaborative_filtering_sync(candidate_id, job_ids, n=5):&#10;    &quot;&quot;&quot;Dự đoán top job cho candidate dựa vào model CF (SVD)&quot;&quot;&quot;&#10;    if not os.path.exists(MODEL_PATH):&#10;        print(&quot;⚠️ CF model not found, returning empty results.&quot;)&#10;        return []&#10;&#10;    model = joblib.load(MODEL_PATH)&#10;    predict = [(job, model.predict(candidate_id, job).est) for job in job_ids]&#10;    predict = sorted(predict, key=lambda x: x[1], reverse=True)[:n]&#10;    return predict&#10;&#10;async def get_collaborative_filtering_recommendations(candidate_id, job_ids, model, n=5):&#10;    &quot;&quot;&quot;Async wrapper for collaborative filtering&quot;&quot;&quot;&#10;    return await sync_to_async(_collaborative_filtering_sync)(candidate_id, job_ids, n)&#10;&#10;&#10;#Hybrid Recommendation can be added here similarly&#10;&#10;async def get_hybrid_job_recommendations(candidate_id: int, query_item: dict, job_ids: list, top_n: int = 5):&#10;    # 1️⃣ Get Content-Based recommendations (semantic + skill overlap)&#10;    content_results = await get_content_based_recommendations(query_item, top_n=top_n * 2)&#10;    content_scores = {r[&quot;job_id&quot;]: r[&quot;similarity&quot;] for r in content_results}&#10;&#10;    # 2️⃣ Try Collaborative Filtering (fallback to None if data too small)&#10;    try:&#10;        cf_results = await get_collaborative_filtering_recommendations(candidate_id, job_ids, model=None, n=top_n * 2)&#10;        cf_scores = {job: score for job, score in cf_results}&#10;        has_cf_data = True&#10;    except Exception as e:&#10;        print(f&quot;[⚠️ CF skipped: {e}]&quot;)&#10;        cf_results = []  # Initialize to empty list when exception occurs&#10;        cf_scores = {}&#10;        has_cf_data = False&#10;&#10;    # 3️⃣ Set dynamic weights&#10;    # New system → content weight high, CF low&#10;    if not has_cf_data:&#10;        content_weight = 1.0&#10;        cf_weight = 0.0&#10;    else:&#10;        content_weight = 0.8  # tune dynamically when more feedback grows&#10;        cf_weight = 0.2&#10;&#10;    # 4️⃣ Combine both scores&#10;    hybrid_combined = {}&#10;    for job_id, c_score in content_scores.items():&#10;        cf_score = cf_scores.get(job_id, 0)&#10;        hybrid_score = (content_weight * c_score) + (cf_weight * cf_score)&#10;        hybrid_combined[job_id] = round(hybrid_score, 4)&#10;&#10;    # 5️⃣ Merge metadata from content results&#10;    hybrid_ranked = sorted(content_results, key=lambda x: hybrid_combined.get(x[&quot;job_id&quot;], 0), reverse=True)[:top_n]&#10;&#10;    # 6️⃣ Attach hybrid score to results&#10;    for r in hybrid_ranked:&#10;        r[&quot;final_score&quot;] = hybrid_combined.get(r[&quot;job_id&quot;], r[&quot;similarity&quot;])&#10;        r[&quot;source_weight&quot;] = {&quot;content&quot;: content_weight, &quot;cf&quot;: cf_weight}&#10;&#10;    return  {&#10;        &quot;content_based&quot;: content_results[:top_n],&#10;        &quot;collaborative&quot;: [{&quot;job_id&quot;: job, &quot;score&quot;: score} for job, score in cf_results[:top_n]],&#10;        &quot;hybrid_top&quot;: hybrid_ranked&#10;    }&#10;&#10;&#10;def _query_all_jobs_sync():&#10;    &quot;&quot;&quot;&#10;    Synchronous function to get ACTIVE jobs from PostgreSQL (ORM)&#10;    &quot;&quot;&quot;&#10;    jobs = JobPostings.objects.filter(status=&quot;ACTIVE&quot;).values(&#10;        &quot;id&quot;, &quot;title&quot;, &quot;description&quot;, &quot;address&quot;&#10;    )&#10;&#10;    # Chuẩn hóa về định dạng mà hybrid model dùng&#10;    job_list = [{&quot;job_id&quot;: job[&quot;id&quot;], &quot;title&quot;: job[&quot;title&quot;],&#10;                 &quot;description&quot;: job[&quot;description&quot;], &quot;address&quot;: job[&quot;address&quot;]}&#10;                for job in jobs]&#10;    return job_list&#10;&#10;def query_all_jobs():&#10;    &quot;&quot;&quot;&#10;    Lấy danh sách job đang ACTIVE từ PostgreSQL (ORM)&#10;    Wrapper for sync context (still synchronous for backward compatibility)&#10;    &quot;&quot;&quot;&#10;    return _query_all_jobs_sync()&#10;&#10;async def query_all_jobs_async():&#10;    &quot;&quot;&quot;&#10;    Async wrapper for query_all_jobs&#10;    &quot;&quot;&quot;&#10;    return await sync_to_async(_query_all_jobs_sync)()&#10;&#10;&#10;# if __name__ == &quot;__main__&quot;:&#10;#     import json&#10;#&#10;#     print(&quot; Starting Content-Based Recommendation Test (with Skill Overlap Weighting)...&quot;)&#10;#     print(&quot;=&quot; * 80)&#10;#&#10;#     query_item = {&#10;#         &quot;skills&quot;: [&quot;Python&quot;, &quot;FastAPI&quot;, &quot;PostgreSQL&quot;, &quot;Docker&quot;, &quot;AWS&quot;],&#10;#         &quot;title&quot;: &quot;Back-end developer&quot;,&#10;#         &quot;description&quot;: &quot;We are looking for a skilled Back-end developer with experience in &quot;&#10;#                        &quot;Python and FastAPI to join our dynamic team. The ideal&quot;&#10;#                        &quot; candidate will have a strong background in building &quot;&#10;#                        &quot;scalable web applications and working with cloud services like AWS. &quot;&#10;#                        &quot;Familiarity with PostgreSQL and containerization using Docker is a must.&quot;&#10;#     }&#10;#&#10;#     print(&quot;\n Query Item:&quot;)&#10;#     print(json.dumps(query_item, indent=2, ensure_ascii=False))&#10;#     print(&quot;\n&quot; + &quot;=&quot; * 80)&#10;#&#10;#     try:&#10;#         print(&quot;\n Searching for similar jobs (Hybrid: Semantic + Skill Overlap)...&quot;)&#10;#         recs = asyncio.run(get_content_based_recommendations(query_item, top_n=5, skill_weight=0.4))&#10;#&#10;#         if not recs:&#10;#             print(&quot;\n❌ No recommendations found. The JobPosting collection might be empty.&quot;)&#10;#         else:&#10;#             print(f&quot;\n✅ Found {len(recs)} recommendations:\n&quot;)&#10;#             for idx, r in enumerate(recs, 1):&#10;#                 print(f&quot;\n{'='*80}&quot;)&#10;#                 print(f&quot;#{idx} - {r['title']}&quot;)&#10;#                 print(f&quot;{'='*80}&quot;)&#10;#                 print(f&quot; Job ID: {r['job_id']}&quot;)&#10;#                 print(f&quot; Skills: {r['skills']}&quot;)&#10;#                 print(f&quot; Scores:&quot;)&#10;#                 print(f&quot;   • Semantic Similarity: {r['semantic_similarity']:.3f}&quot;)&#10;#                 print(f&quot;   • Similarity: {r['similarity']:.3f} (Overall)&quot;)&#10;#                 print(f&quot; Description: {r['description'][:150]}...&quot;)&#10;#&#10;#     except Exception as e:&#10;#         print(f&quot;\n❌ Error occurred: {str(e)}&quot;)&#10;#         import traceback&#10;#         traceback.print_exc()&#10;#&#10;#     finally:&#10;#         # Close the Weaviate connection properly&#10;#         print(&quot;\n&quot; + &quot;=&quot; * 80)&#10;#         print(&quot; Closing connections...&quot;)&#10;#         manager.close()&#10;#         print(&quot;✅ Done!&quot;)&#10;" />
              <option name="updatedContent" value="import asyncio&#10;&#10;import joblib&#10;import numpy as np&#10;import pandas as pd&#10;import os&#10;import django&#10;import sys&#10;from sqlalchemy import create_engine&#10;from asgiref.sync import sync_to_async&#10;&#10;from dotenv import load_dotenv&#10;from google import genai&#10;from surprise import Reader, Dataset, SVD, accuracy&#10;from surprise.model_selection import train_test_split&#10;&#10;from apps.recommendation_agent.services.weaviate_service import query_weaviate_async, manager&#10;from apps.recommendation_agent.services.overlap_skill import calculate_skill_overlap&#10;&#10;load_dotenv()&#10;MODEL_PATH = &quot;cf_model.pkl&quot;&#10;&#10;# Setup Django environment FIRST before importing models&#10;django_base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))&#10;sys.path.append(django_base_dir)&#10;os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'Careermate.settings')&#10;django.setup()&#10;&#10;# NOW import Django models after setup&#10;from django.conf import settings&#10;from apps.recommendation_agent.models import Candidate, JobPostings&#10;&#10;# Create SQLAlchemy engine from Django database settings&#10;def get_sqlalchemy_engine():&#10;    &quot;&quot;&quot;Create SQLAlchemy engine from Django database settings&quot;&quot;&quot;&#10;    db_settings = settings.DATABASES['default']&#10;    engine = db_settings.get('ENGINE', '')&#10;&#10;    if 'postgresql' in engine:&#10;        db_url = f&quot;postgresql://{db_settings['USER']}:{db_settings['PASSWORD']}@{db_settings['HOST']}:{db_settings.get('PORT', 5432)}/{db_settings['NAME']}&quot;&#10;    elif 'mysql' in engine:&#10;        db_url = f&quot;mysql+pymysql://{db_settings['USER']}:{db_settings['PASSWORD']}@{db_settings['HOST']}:{db_settings.get('PORT', 3306)}/{db_settings['NAME']}&quot;&#10;    else:&#10;        # SQLite or other&#10;        db_url = f&quot;sqlite:///{db_settings['NAME']}&quot;&#10;&#10;    return create_engine(db_url)&#10;&#10;# Get the correct path to the CSV file&#10;csv_path = os.path.join(settings.BASE_DIR, 'agent_core', 'data', 'job_postings.csv')&#10;data_jp = pd.read_csv(csv_path, encoding='latin-1')&#10;&#10;#get data from postgres by candidateId&#10;def get_candidate_by_id(candidate_id: int, resume_id: int | None = None) -&gt; dict | None:&#10;    &quot;&quot;&quot;&#10;    Get candidate by ID with their title and skills from resume(s).&#10;&#10;    Args:&#10;        candidate_id: The ID of the candidate&#10;        resume_id: Optional - If provided, only return this specific resume. If None, return all resumes.&#10;&#10;    Returns:&#10;        Dictionary with candidate title and skills from specified resume(s), or None if not found&#10;    &quot;&quot;&quot;&#10;    try:&#10;        candidate = (&#10;            Candidate.objects&#10;            .select_related('account')&#10;            .prefetch_related('resumes__skills')&#10;            .get(candidate_id=candidate_id)&#10;        )&#10;&#10;        resumes_data = []&#10;        # The 'resumes' relationship exists via Resume model's related_name='resumes'&#10;        # IDE may show warning because Candidate has managed=False, but it works at runtime&#10;        all_resumes = candidate.resumes.all().order_by('-created_at')  # type: ignore&#10;&#10;        # If resume_id is provided, filter to get only that specific resume&#10;        if resume_id is not None:&#10;            all_resumes = all_resumes.filter(resume_id=resume_id)&#10;            if not all_resumes.exists():&#10;                return None  # Resume not found for this candidate&#10;&#10;        for resume in all_resumes:&#10;            skills = []&#10;            for skill in resume.skills.all():&#10;                skills.append({&#10;                    &quot;skill_id&quot;: skill.skill_id,&#10;                    &quot;skill_name&quot;: skill.skill_name,&#10;                    &quot;yearOfExperience&quot;: skill.year_of_experience or 0&#10;                })&#10;&#10;            resumes_data.append({&#10;                &quot;title&quot;: candidate.title or &quot;&quot;,&#10;                &quot;resume_id&quot;: resume.resume_id,&#10;                &quot;skills&quot;: skills,&#10;                &quot;skills_count&quot;: len(skills)&#10;            })&#10;&#10;        return {&#10;            &quot;candidate_id&quot;: candidate.candidate_id,&#10;            &quot;title&quot;: candidate.title or &quot;&quot;,&#10;            &quot;resumes&quot;: resumes_data,&#10;        }&#10;    except Candidate.DoesNotExist:&#10;        return None&#10;&#10;#init weaviate&#10;# Initialize Gemini client&#10;gemini_client = genai.Client(api_key=os.getenv(&quot;GOOGLE_API_KEY&quot;))&#10;&#10;def get_gemini_embedding(text: str):&#10;    &quot;&quot;&quot;Tạo vector embedding bằng Gemini (models/embedding-001)&quot;&quot;&quot;&#10;    text = (text or &quot;&quot;).strip()&#10;    if not text:&#10;        return None&#10;&#10;    response = gemini_client.models.embed_content(&#10;        model=&quot;models/embedding-001&quot;,&#10;        contents=text&#10;    )&#10;&#10;    # Trả về list[float] (Weaviate yêu cầu dạng này)&#10;    return np.array(response.embeddings[0].values, dtype=np.float32).tolist()&#10;&#10;&#10;#Content-Based Recommendation with Skill Overlap Weighting&#10;async def get_content_based_recommendations(query_item, top_n=5, weights=None, skill_weight=0.4):&#10;    if weights is None:&#10;        weights = {&quot;skills&quot;: 0.5, &quot;title&quot;: 0.3, &quot;description&quot;: 0.15}&#10;&#10;    # 1️⃣ Combine all fields into weighted text&#10;    def to_text(v):&#10;        if isinstance(v, list):&#10;            return &quot;, &quot;.join(str(x) for x in v)&#10;        return str(v or &quot;&quot;)&#10;&#10;    # Create weighted combined text (repeat important fields to increase their weight)&#10;    skills_text = to_text(query_item.get(&quot;skills&quot;, &quot;&quot;))&#10;    title_text = to_text(query_item.get(&quot;title&quot;, &quot;&quot;))&#10;    description_text = to_text(query_item.get(&quot;description&quot;, &quot;&quot;))&#10;&#10;    # Combine with weights by repeating (simple but effective approach)&#10;    combined_parts = []&#10;    if skills_text:&#10;        combined_parts.extend([skills_text] * int(weights.get(&quot;skills&quot;, 0.5) * 10))  # High weight for skills&#10;    if title_text:&#10;        combined_parts.extend([title_text] * int(weights.get(&quot;title&quot;, 0.3) * 10))  # Medium weight for title&#10;    if description_text:&#10;        combined_parts.extend([description_text] * int(weights.get(&quot;description&quot;, 0.15) * 10))&#10;&#10;    combined_text = &quot; &quot;.join(combined_parts)&#10;&#10;    # 2️⃣ Create single embedding&#10;    # embedding = model.encode(combined_text, normalize_embeddings=True)&#10;    # vector = embedding.tolist()&#10;    vector = get_gemini_embedding(combined_text)&#10;    # 3️⃣ Query Weaviate with single vector (get more results for better filtering)&#10;    results = await query_weaviate_async(vector, limit=top_n * 3)  # Get 3x more for skill filtering&#10;&#10;    # 4️⃣ Calculate hybrid scores combining semantic similarity + skill overlap&#10;    query_skills = query_item.get(&quot;skills&quot;, [])&#10;    if isinstance(query_skills, str):&#10;        query_skills = [s.strip() for s in query_skills.split(&quot;,&quot;)]&#10;&#10;    formatted_results = []&#10;    for job in results:&#10;        # Parse job skills&#10;        job_skills_text = job[&quot;skills&quot;]&#10;        if isinstance(job_skills_text, str):&#10;            job_skills = [s.strip() for s in job_skills_text.split(&quot;,&quot;) if s.strip()]&#10;        else:&#10;            job_skills = []&#10;&#10;        # Calculate semantic similarity (from vector distance)&#10;        semantic_similarity = 1 - job[&quot;distance&quot;]&#10;&#10;        # Calculate skill overlap score&#10;        skill_overlap_score = calculate_skill_overlap(query_skills, job_skills)&#10;&#10;        # Hybrid score: weighted combination&#10;        hybrid_score = (1 - skill_weight) * semantic_similarity + skill_weight * skill_overlap_score&#10;&#10;        formatted_results.append({&#10;            &quot;job_id&quot;: job[&quot;job_id&quot;],&#10;            &quot;title&quot;: job[&quot;title&quot;],&#10;            &quot;skills&quot;: job[&quot;skills&quot;],&#10;            &quot;description&quot;: job.get(&quot;description&quot;, &quot;&quot;),&#10;            &quot;semantic_similarity&quot;: semantic_similarity,&#10;            &quot;similarity&quot;: hybrid_score  # For backward compatibility&#10;        })&#10;&#10;    # 5️⃣ Sort by hybrid score and return top N&#10;    formatted_results.sort(key=lambda x: x[&quot;similarity&quot;], reverse=True)&#10;&#10;    return formatted_results[:top_n]&#10;&#10;&#10;#Collaborative Filtering Recommendation can be added here similarly&#10;def _collaborative_filtering_sync(candidate_id, job_ids, n=5):&#10;    &quot;&quot;&quot;Dự đoán top job cho candidate dựa vào model CF (SVD) với thông tin chi tiết&quot;&quot;&quot;&#10;    if not os.path.exists(MODEL_PATH):&#10;        print(&quot;⚠️ CF model not found, returning empty results.&quot;)&#10;        return []&#10;&#10;    model = joblib.load(MODEL_PATH)&#10;    &#10;    # Predict scores for all jobs&#10;    predictions = [(job_id, model.predict(candidate_id, job_id).est) for job_id in job_ids]&#10;    predictions = sorted(predictions, key=lambda x: x[1], reverse=True)[:n]&#10;    &#10;    # Get detailed job information from database&#10;    predicted_job_ids = [job_id for job_id, _ in predictions]&#10;    jobs = JobPostings.objects.filter(id__in=predicted_job_ids).values(&#10;        'id', 'title', 'description', 'address'&#10;    )&#10;    &#10;    # Create a mapping of job_id to job details&#10;    job_details_map = {job['id']: job for job in jobs}&#10;    &#10;    # Combine predictions with job details&#10;    detailed_results = []&#10;    for job_id, score in predictions:&#10;        job_info = job_details_map.get(job_id, {})&#10;        &#10;        # Get skills from Weaviate or CSV (if available)&#10;        skills = &quot;N/A&quot;&#10;        try:&#10;            # Try to get from data_jp CSV&#10;            job_row = data_jp[data_jp['id'] == job_id]&#10;            if not job_row.empty:&#10;                skills = job_row.iloc[0].get('skills', 'N/A')&#10;        except Exception:&#10;            pass&#10;        &#10;        detailed_results.append({&#10;            &quot;job_id&quot;: job_id,&#10;            &quot;title&quot;: job_info.get('title', 'Unknown'),&#10;            &quot;description&quot;: job_info.get('description', ''),&#10;            &quot;address&quot;: job_info.get('address', ''),&#10;            &quot;skills&quot;: skills,&#10;            &quot;cf_score&quot;: round(score, 4)&#10;        })&#10;    &#10;    return detailed_results&#10;&#10;async def get_collaborative_filtering_recommendations(candidate_id, job_ids, model, n=5):&#10;    &quot;&quot;&quot;Async wrapper for collaborative filtering&quot;&quot;&quot;&#10;    return await sync_to_async(_collaborative_filtering_sync)(candidate_id, job_ids, n)&#10;&#10;&#10;#Hybrid Recommendation can be added here similarly&#10;&#10;async def get_hybrid_job_recommendations(candidate_id: int, query_item: dict, job_ids: list, top_n: int = 5):&#10;    # 1️⃣ Get Content-Based recommendations (semantic + skill overlap)&#10;    content_results = await get_content_based_recommendations(query_item, top_n=top_n * 2)&#10;    content_scores = {r[&quot;job_id&quot;]: r[&quot;similarity&quot;] for r in content_results}&#10;&#10;    # 2️⃣ Try Collaborative Filtering (fallback to None if data too small)&#10;    try:&#10;        cf_results = await get_collaborative_filtering_recommendations(candidate_id, job_ids, model=None, n=top_n * 2)&#10;        # CF results now return detailed dictionaries with job info&#10;        cf_scores = {job[&quot;job_id&quot;]: job[&quot;cf_score&quot;] for job in cf_results}&#10;        has_cf_data = True&#10;    except Exception as e:&#10;        print(f&quot;[⚠️ CF skipped: {e}]&quot;)&#10;        cf_results = []  # Initialize to empty list when exception occurs&#10;        cf_scores = {}&#10;        has_cf_data = False&#10;&#10;    # 3️⃣ Set dynamic weights&#10;    # New system → content weight high, CF low&#10;    if not has_cf_data:&#10;        content_weight = 1.0&#10;        cf_weight = 0.0&#10;    else:&#10;        content_weight = 0.8  # tune dynamically when more feedback grows&#10;        cf_weight = 0.2&#10;&#10;    # 4️⃣ Combine both scores&#10;    hybrid_combined = {}&#10;    for job_id, c_score in content_scores.items():&#10;        cf_score = cf_scores.get(job_id, 0)&#10;        hybrid_score = (content_weight * c_score) + (cf_weight * cf_score)&#10;        hybrid_combined[job_id] = round(hybrid_score, 4)&#10;&#10;    # 5️⃣ Merge metadata from content results&#10;    hybrid_ranked = sorted(content_results, key=lambda x: hybrid_combined.get(x[&quot;job_id&quot;], 0), reverse=True)[:top_n]&#10;&#10;    # 6️⃣ Attach hybrid score to results&#10;    for r in hybrid_ranked:&#10;        r[&quot;final_score&quot;] = hybrid_combined.get(r[&quot;job_id&quot;], r[&quot;similarity&quot;])&#10;        r[&quot;source_weight&quot;] = {&quot;content&quot;: content_weight, &quot;cf&quot;: cf_weight}&#10;&#10;    return  {&#10;        &quot;content_based&quot;: content_results[:top_n],&#10;        &quot;collaborative&quot;: cf_results[:top_n],  # Now returns detailed job info&#10;        &quot;hybrid_top&quot;: hybrid_ranked&#10;    }&#10;&#10;&#10;def _query_all_jobs_sync():&#10;    &quot;&quot;&quot;&#10;    Synchronous function to get ACTIVE jobs from PostgreSQL (ORM)&#10;    &quot;&quot;&quot;&#10;    jobs = JobPostings.objects.filter(status=&quot;ACTIVE&quot;).values(&#10;        &quot;id&quot;, &quot;title&quot;, &quot;description&quot;, &quot;address&quot;&#10;    )&#10;&#10;    # Chuẩn hóa về định dạng mà hybrid model dùng&#10;    job_list = [{&quot;job_id&quot;: job[&quot;id&quot;], &quot;title&quot;: job[&quot;title&quot;],&#10;                 &quot;description&quot;: job[&quot;description&quot;], &quot;address&quot;: job[&quot;address&quot;]}&#10;                for job in jobs]&#10;    return job_list&#10;&#10;def query_all_jobs():&#10;    &quot;&quot;&quot;&#10;    Lấy danh sách job đang ACTIVE từ PostgreSQL (ORM)&#10;    Wrapper for sync context (still synchronous for backward compatibility)&#10;    &quot;&quot;&quot;&#10;    return _query_all_jobs_sync()&#10;&#10;async def query_all_jobs_async():&#10;    &quot;&quot;&quot;&#10;    Async wrapper for query_all_jobs&#10;    &quot;&quot;&quot;&#10;    return await sync_to_async(_query_all_jobs_sync)()&#10;&#10;&#10;# if __name__ == &quot;__main__&quot;:&#10;#     import json&#10;#&#10;#     print(&quot; Starting Content-Based Recommendation Test (with Skill Overlap Weighting)...&quot;)&#10;#     print(&quot;=&quot; * 80)&#10;#&#10;#     query_item = {&#10;#         &quot;skills&quot;: [&quot;Python&quot;, &quot;FastAPI&quot;, &quot;PostgreSQL&quot;, &quot;Docker&quot;, &quot;AWS&quot;],&#10;#         &quot;title&quot;: &quot;Back-end developer&quot;,&#10;#         &quot;description&quot;: &quot;We are looking for a skilled Back-end developer with experience in &quot;&#10;#                        &quot;Python and FastAPI to join our dynamic team. The ideal&quot;&#10;#                        &quot; candidate will have a strong background in building &quot;&#10;#                        &quot;scalable web applications and working with cloud services like AWS. &quot;&#10;#                        &quot;Familiarity with PostgreSQL and containerization using Docker is a must.&quot;&#10;#     }&#10;#&#10;#     print(&quot;\n Query Item:&quot;)&#10;#     print(json.dumps(query_item, indent=2, ensure_ascii=False))&#10;#     print(&quot;\n&quot; + &quot;=&quot; * 80)&#10;#&#10;#     try:&#10;#         print(&quot;\n Searching for similar jobs (Hybrid: Semantic + Skill Overlap)...&quot;)&#10;#         recs = asyncio.run(get_content_based_recommendations(query_item, top_n=5, skill_weight=0.4))&#10;#&#10;#         if not recs:&#10;#             print(&quot;\n❌ No recommendations found. The JobPosting collection might be empty.&quot;)&#10;#         else:&#10;#             print(f&quot;\n✅ Found {len(recs)} recommendations:\n&quot;)&#10;#             for idx, r in enumerate(recs, 1):&#10;#                 print(f&quot;\n{'='*80}&quot;)&#10;#                 print(f&quot;#{idx} - {r['title']}&quot;)&#10;#                 print(f&quot;{'='*80}&quot;)&#10;#                 print(f&quot; Job ID: {r['job_id']}&quot;)&#10;#                 print(f&quot; Skills: {r['skills']}&quot;)&#10;#                 print(f&quot; Scores:&quot;)&#10;#                 print(f&quot;   • Semantic Similarity: {r['semantic_similarity']:.3f}&quot;)&#10;#                 print(f&quot;   • Similarity: {r['similarity']:.3f} (Overall)&quot;)&#10;#                 print(f&quot; Description: {r['description'][:150]}...&quot;)&#10;#&#10;#     except Exception as e:&#10;#         print(f&quot;\n❌ Error occurred: {str(e)}&quot;)&#10;#         import traceback&#10;#         traceback.print_exc()&#10;#&#10;#     finally:&#10;#         # Close the Weaviate connection properly&#10;#         print(&quot;\n&quot; + &quot;=&quot; * 80)&#10;#         print(&quot; Closing connections...&quot;)&#10;#         manager.close()&#10;#         print(&quot;✅ Done!&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/apps/recommendation_agent/services/test_collaborative_filtering.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/apps/recommendation_agent/services/test_collaborative_filtering.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;Test script for Collaborative Filtering Recommendations&#10;Kiểm tra dữ liệu trả về từ collaborative filtering model&#10;&quot;&quot;&quot;&#10;import os&#10;import django&#10;import sys&#10;import asyncio&#10;import pandas as pd&#10;from sqlalchemy import create_engine&#10;&#10;# Setup Django environment&#10;django_base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))&#10;sys.path.append(django_base_dir)&#10;os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'Careermate.settings')&#10;django.setup()&#10;&#10;from django.conf import settings&#10;from apps.recommendation_agent.services.recommendation_system import (&#10;    get_collaborative_filtering_recommendations,&#10;    get_hybrid_job_recommendations,&#10;    query_all_jobs_async&#10;)&#10;&#10;&#10;def get_sqlalchemy_engine():&#10;    &quot;&quot;&quot;Create SQLAlchemy engine from Django database settings&quot;&quot;&quot;&#10;    db_settings = settings.DATABASES['default']&#10;    engine = db_settings.get('ENGINE', '')&#10;&#10;    if 'postgresql' in engine:&#10;        db_url = f&quot;postgresql://{db_settings['USER']}:{db_settings['PASSWORD']}@{db_settings['HOST']}:{db_settings.get('PORT', 5432)}/{db_settings['NAME']}&quot;&#10;    elif 'mysql' in engine:&#10;        db_url = f&quot;mysql+pymysql://{db_settings['USER']}:{db_settings['PASSWORD']}@{db_settings['HOST']}:{db_settings.get('PORT', 3306)}/{db_settings['NAME']}&quot;&#10;    else:&#10;        db_url = f&quot;sqlite:///{db_settings['NAME']}&quot;&#10;&#10;    return create_engine(db_url)&#10;&#10;&#10;def check_feedback_data():&#10;    &quot;&quot;&quot;Kiểm tra dữ liệu feedback trong database&quot;&quot;&quot;&#10;    print(&quot;=&quot; * 80)&#10;    print(&quot; KIỂM TRA DỮ LIỆU FEEDBACK&quot;)&#10;    print(&quot;=&quot; * 80)&#10;&#10;    engine = get_sqlalchemy_engine()&#10;    try:&#10;        # Lấy tất cả feedback data&#10;        query = &quot;SELECT candidate_id, job_id, score FROM job_feedback&quot;&#10;        df = pd.read_sql(query, engine)&#10;&#10;        if df.empty:&#10;            print(&quot;\n❌ Không có dữ liệu feedback trong database!&quot;)&#10;            print(&quot; Hãy thêm dữ liệu feedback trước khi test collaborative filtering.&quot;)&#10;            return False&#10;&#10;        print(f&quot;\n✅ Tổng số feedback records: {len(df)}&quot;)&#10;        print(f&quot; Số candidates có feedback: {df['candidate_id'].nunique()}&quot;)&#10;        print(f&quot; Số jobs có feedback: {df['job_id'].nunique()}&quot;)&#10;        print(f&quot; Score trung bình: {df['score'].mean():.3f}&quot;)&#10;        print(f&quot; Score min/max: {df['score'].min():.3f} / {df['score'].max():.3f}&quot;)&#10;&#10;        # Hiển thị 10 records đầu tiên&#10;        print(&quot;\n Sample feedback data (10 records đầu tiên):&quot;)&#10;        print(df.head(10).to_string(index=False))&#10;&#10;        # Thống kê theo candidate&#10;        print(&quot;\n Top 5 candidates có nhiều feedback nhất:&quot;)&#10;        candidate_counts = df['candidate_id'].value_counts().head(5)&#10;        for candidate_id, count in candidate_counts.items():&#10;            avg_score = df[df['candidate_id'] == candidate_id]['score'].mean()&#10;            print(f&quot;   Candidate {candidate_id}: {count} feedbacks (avg score: {avg_score:.3f})&quot;)&#10;&#10;        return True&#10;    finally:&#10;        engine.dispose()&#10;&#10;&#10;async def test_collaborative_filtering(candidate_id=None, top_n=5):&#10;    &quot;&quot;&quot;Test collaborative filtering recommendations&quot;&quot;&quot;&#10;    print(&quot;\n&quot; + &quot;=&quot; * 80)&#10;    print(&quot; TEST COLLABORATIVE FILTERING&quot;)&#10;    print(&quot;=&quot; * 80)&#10;&#10;    # Nếu không có candidate_id, lấy candidate đầu tiên có feedback&#10;    if candidate_id is None:&#10;        engine = get_sqlalchemy_engine()&#10;        try:&#10;            query = &quot;SELECT DISTINCT candidate_id FROM job_feedback LIMIT 1&quot;&#10;            df = pd.read_sql(query, engine)&#10;            if df.empty:&#10;                print(&quot;\n❌ Không có candidate nào có feedback!&quot;)&#10;                return&#10;            candidate_id = df['candidate_id'].iloc[0]&#10;        finally:&#10;            engine.dispose()&#10;&#10;    print(f&quot;\n Testing với Candidate ID: {candidate_id}&quot;)&#10;    print(f&quot; Số recommendations yêu cầu: {top_n}&quot;)&#10;&#10;    # Lấy danh sách job IDs&#10;    job_ids = [j[&quot;job_id&quot;] for j in await query_all_jobs_async()]&#10;    print(f&quot; Tổng số jobs trong hệ thống: {len(job_ids)}&quot;)&#10;&#10;    try:&#10;        print(&quot;\n⏳ Đang chạy collaborative filtering...&quot;)&#10;        cf_results = await get_collaborative_filtering_recommendations(&#10;            candidate_id=candidate_id,&#10;            job_ids=job_ids,&#10;            model=None,&#10;            n=top_n&#10;        )&#10;&#10;        print(f&quot;\n✅ Collaborative Filtering hoàn tất!&quot;)&#10;        print(f&quot; Số recommendations trả về: {len(cf_results)}&quot;)&#10;&#10;        print(&quot;\n&quot; + &quot;=&quot; * 80)&#10;        print(&quot; KẾT QUẢ COLLABORATIVE FILTERING:&quot;)&#10;        print(&quot;=&quot; * 80)&#10;&#10;        for idx, (job_id, score) in enumerate(cf_results, 1):&#10;            print(f&quot;\n#{idx} - Job ID: {job_id}&quot;)&#10;            print(f&quot;   ⭐ Predicted Score: {score:.4f}&quot;)&#10;&#10;        return cf_results&#10;&#10;    except Exception as e:&#10;        print(f&quot;\n❌ Lỗi khi chạy collaborative filtering: {str(e)}&quot;)&#10;        import traceback&#10;        traceback.print_exc()&#10;        return None&#10;&#10;&#10;async def test_hybrid_recommendations(candidate_id=None, top_n=5):&#10;    &quot;&quot;&quot;Test hybrid recommendations (Content-Based + Collaborative Filtering)&quot;&quot;&quot;&#10;    print(&quot;\n&quot; + &quot;=&quot; * 80)&#10;    print(&quot; TEST HYBRID RECOMMENDATIONS&quot;)&#10;    print(&quot;=&quot; * 80)&#10;&#10;    # Nếu không có candidate_id, lấy candidate đầu tiên có feedback&#10;    if candidate_id is None:&#10;        engine = get_sqlalchemy_engine()&#10;        try:&#10;            query = &quot;SELECT DISTINCT candidate_id FROM job_feedback LIMIT 1&quot;&#10;            df = pd.read_sql(query, engine)&#10;            if df.empty:&#10;                print(&quot;\n❌ Không có candidate nào có feedback!&quot;)&#10;                return&#10;            candidate_id = df['candidate_id'].iloc[0]&#10;        finally:&#10;            engine.dispose()&#10;&#10;    print(f&quot;\n Testing với Candidate ID: {candidate_id}&quot;)&#10;&#10;    # Sample query item&#10;    query_item = {&#10;        &quot;skills&quot;: [&quot;Python&quot;, &quot;Django&quot;, &quot;PostgreSQL&quot;, &quot;REST API&quot;],&#10;        &quot;title&quot;: &quot;Backend Developer&quot;,&#10;        &quot;description&quot;: &quot;Experienced backend developer with strong Python skills&quot;&#10;    }&#10;&#10;    print(f&quot;\n Query Item:&quot;)&#10;    print(f&quot;   Skills: {', '.join(query_item['skills'])}&quot;)&#10;    print(f&quot;   Title: {query_item['title']}&quot;)&#10;&#10;    # Lấy danh sách job IDs&#10;    job_ids = [j[&quot;job_id&quot;] for j in await query_all_jobs_async()]&#10;&#10;    try:&#10;        print(&quot;\n⏳ Đang chạy hybrid recommendations...&quot;)&#10;        hybrid_results = await get_hybrid_job_recommendations(&#10;            candidate_id=candidate_id,&#10;            query_item=query_item,&#10;            job_ids=job_ids,&#10;            top_n=top_n&#10;        )&#10;&#10;        print(f&quot;\n✅ Hybrid Recommendations hoàn tất!&quot;)&#10;&#10;        # Content-Based Results&#10;        print(&quot;\n&quot; + &quot;=&quot; * 80)&#10;        print(&quot; CONTENT-BASED RECOMMENDATIONS:&quot;)&#10;        print(&quot;=&quot; * 80)&#10;        for idx, job in enumerate(hybrid_results['content_based'], 1):&#10;            print(f&quot;\n#{idx} - {job['title']}&quot;)&#10;            print(f&quot;   Job ID: {job['job_id']}&quot;)&#10;            print(f&quot;   ⭐ Similarity Score: {job['similarity']:.4f}&quot;)&#10;            print(f&quot;    Semantic Similarity: {job['semantic_similarity']:.4f}&quot;)&#10;            print(f&quot;   Skills: {job['skills'][:100]}...&quot;)&#10;&#10;        # Collaborative Filtering Results&#10;        print(&quot;\n&quot; + &quot;=&quot; * 80)&#10;        print(&quot; COLLABORATIVE FILTERING RECOMMENDATIONS:&quot;)&#10;        print(&quot;=&quot; * 80)&#10;        if hybrid_results['collaborative']:&#10;            for idx, cf_job in enumerate(hybrid_results['collaborative'], 1):&#10;                print(f&quot;\n#{idx} - Job ID: {cf_job['job_id']}&quot;)&#10;                print(f&quot;   ⭐ CF Score: {cf_job['score']:.4f}&quot;)&#10;        else:&#10;            print(&quot;\n⚠️ Không có CF recommendations (có thể do thiếu dữ liệu)&quot;)&#10;&#10;        # Hybrid Results&#10;        print(&quot;\n&quot; + &quot;=&quot; * 80)&#10;        print(&quot; HYBRID RECOMMENDATIONS (FINAL):&quot;)&#10;        print(&quot;=&quot; * 80)&#10;        for idx, job in enumerate(hybrid_results['hybrid_top'], 1):&#10;            print(f&quot;\n#{idx} - {job['title']}&quot;)&#10;            print(f&quot;   Job ID: {job['job_id']}&quot;)&#10;            print(f&quot;   ⭐ Final Score: {job['final_score']:.4f}&quot;)&#10;            print(f&quot;    Weights: Content={job['source_weight']['content']:.2f}, CF={job['source_weight']['cf']:.2f}&quot;)&#10;            print(f&quot;   Skills: {job['skills'][:100]}...&quot;)&#10;&#10;        return hybrid_results&#10;&#10;    except Exception as e:&#10;        print(f&quot;\n❌ Lỗi khi chạy hybrid recommendations: {str(e)}&quot;)&#10;        import traceback&#10;        traceback.print_exc()&#10;        return None&#10;&#10;&#10;async def main():&#10;    &quot;&quot;&quot;Main test function&quot;&quot;&quot;&#10;    print(&quot; COLLABORATIVE FILTERING TEST SUITE&quot;)&#10;    print(&quot;=&quot; * 80)&#10;&#10;    # 1. Kiểm tra dữ liệu feedback&#10;    has_data = check_feedback_data()&#10;&#10;    if not has_data:&#10;        print(&quot;\n Hướng dẫn thêm dữ liệu feedback:&quot;)&#10;        print(&quot;   1. Sử dụng API để candidates tương tác với jobs&quot;)&#10;        print(&quot;   2. Hoặc chạy script seed_feedback_data.py để tạo dữ liệu mẫu&quot;)&#10;        return&#10;&#10;    # 2. Test Collaborative Filtering&#10;    cf_results = await test_collaborative_filtering(candidate_id=None, top_n=5)&#10;&#10;    # 3. Test Hybrid Recommendations&#10;    if cf_results:&#10;        await test_hybrid_recommendations(candidate_id=None, top_n=5)&#10;&#10;    print(&quot;\n&quot; + &quot;=&quot; * 80)&#10;    print(&quot;✅ TEST HOÀN TẤT!&quot;)&#10;    print(&quot;=&quot; * 80)&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    asyncio.run(main())&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;Test script for Collaborative Filtering Recommendations&#10;Kiểm tra dữ liệu trả về từ collaborative filtering model&#10;&quot;&quot;&quot;&#10;import os&#10;import django&#10;import sys&#10;import asyncio&#10;import pandas as pd&#10;from sqlalchemy import create_engine&#10;&#10;# Setup Django environment&#10;django_base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))&#10;sys.path.append(django_base_dir)&#10;os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'Careermate.settings')&#10;django.setup()&#10;&#10;from django.conf import settings&#10;from apps.recommendation_agent.services.recommendation_system import (&#10;    get_collaborative_filtering_recommendations,&#10;    get_hybrid_job_recommendations,&#10;    query_all_jobs_async&#10;)&#10;&#10;&#10;def get_sqlalchemy_engine():&#10;    &quot;&quot;&quot;Create SQLAlchemy engine from Django database settings&quot;&quot;&quot;&#10;    db_settings = settings.DATABASES['default']&#10;    engine = db_settings.get('ENGINE', '')&#10;&#10;    if 'postgresql' in engine:&#10;        db_url = f&quot;postgresql://{db_settings['USER']}:{db_settings['PASSWORD']}@{db_settings['HOST']}:{db_settings.get('PORT', 5432)}/{db_settings['NAME']}&quot;&#10;    elif 'mysql' in engine:&#10;        db_url = f&quot;mysql+pymysql://{db_settings['USER']}:{db_settings['PASSWORD']}@{db_settings['HOST']}:{db_settings.get('PORT', 3306)}/{db_settings['NAME']}&quot;&#10;    else:&#10;        db_url = f&quot;sqlite:///{db_settings['NAME']}&quot;&#10;&#10;    return create_engine(db_url)&#10;&#10;&#10;def check_feedback_data():&#10;    &quot;&quot;&quot;Kiểm tra dữ liệu feedback trong database&quot;&quot;&quot;&#10;    print(&quot;=&quot; * 80)&#10;    print(&quot; KIỂM TRA DỮ LIỆU FEEDBACK&quot;)&#10;    print(&quot;=&quot; * 80)&#10;&#10;    engine = get_sqlalchemy_engine()&#10;    try:&#10;        # Lấy tất cả feedback data&#10;        query = &quot;SELECT candidate_id, job_id, score FROM job_feedback&quot;&#10;        df = pd.read_sql(query, engine)&#10;&#10;        if df.empty:&#10;            print(&quot;\n❌ Không có dữ liệu feedback trong database!&quot;)&#10;            print(&quot; Hãy thêm dữ liệu feedback trước khi test collaborative filtering.&quot;)&#10;            return False&#10;&#10;        print(f&quot;\n✅ Tổng số feedback records: {len(df)}&quot;)&#10;        print(f&quot; Số candidates có feedback: {df['candidate_id'].nunique()}&quot;)&#10;        print(f&quot; Số jobs có feedback: {df['job_id'].nunique()}&quot;)&#10;        print(f&quot; Score trung bình: {df['score'].mean():.3f}&quot;)&#10;        print(f&quot; Score min/max: {df['score'].min():.3f} / {df['score'].max():.3f}&quot;)&#10;&#10;        # Hiển thị 10 records đầu tiên&#10;        print(&quot;\n Sample feedback data (10 records đầu tiên):&quot;)&#10;        print(df.head(10).to_string(index=False))&#10;&#10;        # Thống kê theo candidate&#10;        print(&quot;\n Top 5 candidates có nhiều feedback nhất:&quot;)&#10;        candidate_counts = df['candidate_id'].value_counts().head(5)&#10;        for candidate_id, count in candidate_counts.items():&#10;            avg_score = df[df['candidate_id'] == candidate_id]['score'].mean()&#10;            print(f&quot;   Candidate {candidate_id}: {count} feedbacks (avg score: {avg_score:.3f})&quot;)&#10;&#10;        return True&#10;    finally:&#10;        engine.dispose()&#10;&#10;&#10;async def test_collaborative_filtering(candidate_id=None, top_n=5):&#10;    &quot;&quot;&quot;Test collaborative filtering recommendations&quot;&quot;&quot;&#10;    print(&quot;\n&quot; + &quot;=&quot; * 80)&#10;    print(&quot; TEST COLLABORATIVE FILTERING&quot;)&#10;    print(&quot;=&quot; * 80)&#10;&#10;    # Nếu không có candidate_id, lấy candidate đầu tiên có feedback&#10;    if candidate_id is None:&#10;        engine = get_sqlalchemy_engine()&#10;        try:&#10;            query = &quot;SELECT DISTINCT candidate_id FROM job_feedback LIMIT 1&quot;&#10;            df = pd.read_sql(query, engine)&#10;            if df.empty:&#10;                print(&quot;\n❌ Không có candidate nào có feedback!&quot;)&#10;                return&#10;            candidate_id = df['candidate_id'].iloc[0]&#10;        finally:&#10;            engine.dispose()&#10;&#10;    print(f&quot;\n Testing với Candidate ID: {candidate_id}&quot;)&#10;    print(f&quot; Số recommendations yêu cầu: {top_n}&quot;)&#10;&#10;    # Lấy danh sách job IDs&#10;    job_ids = [j[&quot;job_id&quot;] for j in await query_all_jobs_async()]&#10;    print(f&quot; Tổng số jobs trong hệ thống: {len(job_ids)}&quot;)&#10;&#10;    try:&#10;        print(&quot;\n⏳ Đang chạy collaborative filtering...&quot;)&#10;        cf_results = await get_collaborative_filtering_recommendations(&#10;            candidate_id=candidate_id,&#10;            job_ids=job_ids,&#10;            model=None,&#10;            n=top_n&#10;        )&#10;&#10;        print(f&quot;\n✅ Collaborative Filtering hoàn tất!&quot;)&#10;        print(f&quot; Số recommendations trả về: {len(cf_results)}&quot;)&#10;&#10;        print(&quot;\n&quot; + &quot;=&quot; * 80)&#10;        print(&quot; KẾT QUẢ COLLABORATIVE FILTERING:&quot;)&#10;        print(&quot;=&quot; * 80)&#10;&#10;        for idx, job in enumerate(cf_results, 1):&#10;            print(f&quot;\n#{idx} - {job['title']}&quot;)&#10;            print(f&quot;   Job ID: {job['job_id']}&quot;)&#10;            print(f&quot;   ⭐ CF Score: {job['cf_score']:.4f}&quot;)&#10;            print(f&quot;    Address: {job.get('address', 'N/A')}&quot;)&#10;            print(f&quot;   ️  Skills: {job.get('skills', 'N/A')}&quot;)&#10;            print(f&quot;    Title: {job.get('title', 'N/A')}&quot;)&#10;            if job.get('description'):&#10;                print(f&quot;    Description: {job['description'][:150]}...&quot;)&#10;&#10;        return cf_results&#10;&#10;    except Exception as e:&#10;        print(f&quot;\n❌ Lỗi khi chạy collaborative filtering: {str(e)}&quot;)&#10;        import traceback&#10;        traceback.print_exc()&#10;        return None&#10;&#10;&#10;async def test_hybrid_recommendations(candidate_id=None, top_n=5):&#10;    &quot;&quot;&quot;Test hybrid recommendations (Content-Based + Collaborative Filtering)&quot;&quot;&quot;&#10;    print(&quot;\n&quot; + &quot;=&quot; * 80)&#10;    print(&quot; TEST HYBRID RECOMMENDATIONS&quot;)&#10;    print(&quot;=&quot; * 80)&#10;&#10;    # Nếu không có candidate_id, lấy candidate đầu tiên có feedback&#10;    if candidate_id is None:&#10;        engine = get_sqlalchemy_engine()&#10;        try:&#10;            query = &quot;SELECT DISTINCT candidate_id FROM job_feedback LIMIT 1&quot;&#10;            df = pd.read_sql(query, engine)&#10;            if df.empty:&#10;                print(&quot;\n❌ Không có candidate nào có feedback!&quot;)&#10;                return&#10;            candidate_id = df['candidate_id'].iloc[0]&#10;        finally:&#10;            engine.dispose()&#10;&#10;    print(f&quot;\n Testing với Candidate ID: {candidate_id}&quot;)&#10;&#10;    # Sample query item&#10;    query_item = {&#10;        &quot;skills&quot;: [&quot;Python&quot;, &quot;Django&quot;, &quot;PostgreSQL&quot;, &quot;REST API&quot;],&#10;        &quot;title&quot;: &quot;Backend Developer&quot;,&#10;        &quot;description&quot;: &quot;Experienced backend developer with strong Python skills&quot;&#10;    }&#10;&#10;    print(f&quot;\n Query Item:&quot;)&#10;    print(f&quot;   Skills: {', '.join(query_item['skills'])}&quot;)&#10;    print(f&quot;   Title: {query_item['title']}&quot;)&#10;&#10;    # Lấy danh sách job IDs&#10;    job_ids = [j[&quot;job_id&quot;] for j in await query_all_jobs_async()]&#10;&#10;    try:&#10;        print(&quot;\n⏳ Đang chạy hybrid recommendations...&quot;)&#10;        hybrid_results = await get_hybrid_job_recommendations(&#10;            candidate_id=candidate_id,&#10;            query_item=query_item,&#10;            job_ids=job_ids,&#10;            top_n=top_n&#10;        )&#10;&#10;        print(f&quot;\n✅ Hybrid Recommendations hoàn tất!&quot;)&#10;&#10;        # Content-Based Results&#10;        print(&quot;\n&quot; + &quot;=&quot; * 80)&#10;        print(&quot; CONTENT-BASED RECOMMENDATIONS:&quot;)&#10;        print(&quot;=&quot; * 80)&#10;        for idx, job in enumerate(hybrid_results['content_based'], 1):&#10;            print(f&quot;\n#{idx} - {job['title']}&quot;)&#10;            print(f&quot;   Job ID: {job['job_id']}&quot;)&#10;            print(f&quot;   ⭐ Similarity Score: {job['similarity']:.4f}&quot;)&#10;            print(f&quot;    Semantic Similarity: {job['semantic_similarity']:.4f}&quot;)&#10;            print(f&quot;   Skills: {job['skills'][:100]}...&quot;)&#10;&#10;        # Collaborative Filtering Results&#10;        print(&quot;\n&quot; + &quot;=&quot; * 80)&#10;        print(&quot; COLLABORATIVE FILTERING RECOMMENDATIONS:&quot;)&#10;        print(&quot;=&quot; * 80)&#10;        if hybrid_results['collaborative']:&#10;            for idx, cf_job in enumerate(hybrid_results['collaborative'], 1):&#10;                print(f&quot;\n#{idx} - {cf_job['title']}&quot;)&#10;                print(f&quot;   Job ID: {cf_job['job_id']}&quot;)&#10;                print(f&quot;   ⭐ CF Score: {cf_job['cf_score']:.4f}&quot;)&#10;                print(f&quot;    Address: {cf_job.get('address', 'N/A')}&quot;)&#10;                print(f&quot;   ️  Skills: {cf_job.get('skills', 'N/A')[:80]}...&quot;)&#10;        else:&#10;            print(&quot;\n⚠️ Không có CF recommendations (có thể do thiếu dữ liệu)&quot;)&#10;&#10;        # Hybrid Results&#10;        print(&quot;\n&quot; + &quot;=&quot; * 80)&#10;        print(&quot; HYBRID RECOMMENDATIONS (FINAL):&quot;)&#10;        print(&quot;=&quot; * 80)&#10;        for idx, job in enumerate(hybrid_results['hybrid_top'], 1):&#10;            print(f&quot;\n#{idx} - {job['title']}&quot;)&#10;            print(f&quot;   Job ID: {job['job_id']}&quot;)&#10;            print(f&quot;   ⭐ Final Score: {job['final_score']:.4f}&quot;)&#10;            print(f&quot;    Weights: Content={job['source_weight']['content']:.2f}, CF={job['source_weight']['cf']:.2f}&quot;)&#10;            print(f&quot;   Skills: {job['skills'][:100]}...&quot;)&#10;&#10;        return hybrid_results&#10;&#10;    except Exception as e:&#10;        print(f&quot;\n❌ Lỗi khi chạy hybrid recommendations: {str(e)}&quot;)&#10;        import traceback&#10;        traceback.print_exc()&#10;        return None&#10;&#10;&#10;async def main():&#10;    &quot;&quot;&quot;Main test function&quot;&quot;&quot;&#10;    print(&quot; COLLABORATIVE FILTERING TEST SUITE&quot;)&#10;    print(&quot;=&quot; * 80)&#10;&#10;    # 1. Kiểm tra dữ liệu feedback&#10;    has_data = check_feedback_data()&#10;&#10;    if not has_data:&#10;        print(&quot;\n Hướng dẫn thêm dữ liệu feedback:&quot;)&#10;        print(&quot;   1. Sử dụng API để candidates tương tác với jobs&quot;)&#10;        print(&quot;   2. Hoặc chạy script seed_feedback_data.py để tạo dữ liệu mẫu&quot;)&#10;        return&#10;&#10;    # 2. Test Collaborative Filtering&#10;    cf_results = await test_collaborative_filtering(candidate_id=None, top_n=5)&#10;&#10;    # 3. Test Hybrid Recommendations&#10;    if cf_results:&#10;        await test_hybrid_recommendations(candidate_id=None, top_n=5)&#10;&#10;    print(&quot;\n&quot; + &quot;=&quot; * 80)&#10;    print(&quot;✅ TEST HOÀN TẤT!&quot;)&#10;    print(&quot;=&quot; * 80)&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    asyncio.run(main())" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>