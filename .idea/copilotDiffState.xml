<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/RATE_LIMIT_OPTIMIZATION.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/RATE_LIMIT_OPTIMIZATION.md" />
              <option name="updatedContent" value="#  Rate Limit Optimization - CV Analysis API&#10;&#10;##  Tóm tắt vấn đề&#10;Người dùng gặp lỗi **429 Too Many Requests** khi gọi API `/api/v1/cv/analyze-ats/` liên tục 2 lần với thông báo:&#10;```json&#10;{&#10;  &quot;detail&quot;: &quot;Too many requests. Try again in 16s&quot;,&#10;  &quot;reason&quot;: &quot;interval&quot;,&#10;  &quot;retry_after&quot;: 16,&#10;  &quot;plan&quot;: &quot;free&quot;&#10;}&#10;```&#10;&#10;## ✅ Các thay đổi đã thực hiện&#10;&#10;### 1. **Giảm Rate Limit cho FREE Plan**&#10;**File**: `apps/cv_analysis_agent/utils/rate_limit.py`&#10;&#10;**Trước:**&#10;- Daily quota: 5 requests/day&#10;- Interval: 30 seconds between requests&#10;&#10;**Sau:**&#10;- Daily quota: **10 requests/day** (tăng 2x)&#10;- Interval: **10 seconds** between requests (giảm 3x)&#10;&#10;### 2. **Cache-First Strategy**&#10;**File**: `apps/cv_analysis_agent/view/resume_analysis_view.py`&#10;&#10;**Cải tiến:**&#10;- ✅ Kiểm tra cache **TRƯỚC** khi áp dụng rate limit&#10;- ✅ Cache hit **KHÔNG tính vào quota**&#10;- ✅ Cache hit trả về **ngay lập tức** (&lt; 100ms)&#10;- ✅ Người dùng có thể gọi API nhiều lần với cùng CV/JD mà không bị giới hạn&#10;&#10;### 3. **Thêm `force_refresh` Parameter**&#10;Người dùng có thể bypass cache nếu muốn phân tích lại:&#10;```bash&#10;# Gọi bình thường (sử dụng cache)&#10;curl -X POST http://localhost:8000/api/v1/cv/analyze-ats/ \&#10;  -F &quot;cv_file=@resume.pdf&quot; \&#10;  -F &quot;job_description=...&quot;&#10;&#10;# Force refresh (bỏ qua cache)&#10;curl -X POST http://localhost:8000/api/v1/cv/analyze-ats/ \&#10;  -F &quot;cv_file=@resume.pdf&quot; \&#10;  -F &quot;job_description=...&quot; \&#10;  -F &quot;force_refresh=true&quot;&#10;```&#10;&#10;### 4. **Thông tin Cache trong Response**&#10;Response sẽ cho biết request có hit cache hay không:&#10;&#10;**Cache HIT (không tốn quota):**&#10;```json&#10;{&#10;  &quot;overall_score&quot;: 85,&#10;  &quot;summary&quot;: {...},&#10;  &quot;rate_limit&quot;: {&#10;    &quot;plan&quot;: &quot;free&quot;,&#10;    &quot;cached&quot;: true,&#10;    &quot;quota_used&quot;: false,&#10;    &quot;tip&quot;: &quot;This result was served from cache and did not consume your quota.&quot;&#10;  },&#10;  &quot;cache&quot;: {&#10;    &quot;hit&quot;: true,&#10;    &quot;age_seconds&quot;: 120&#10;  }&#10;}&#10;```&#10;&#10;**Cache MISS (tốn quota):**&#10;```json&#10;{&#10;  &quot;overall_score&quot;: 85,&#10;  &quot;summary&quot;: {...},&#10;  &quot;rate_limit&quot;: {&#10;    &quot;plan&quot;: &quot;free&quot;,&#10;    &quot;cached&quot;: false,&#10;    &quot;quota_used&quot;: true,&#10;    &quot;remaining_today&quot;: 9,&#10;    &quot;interval_lock&quot;: 10&#10;  }&#10;}&#10;```&#10;&#10;##  Kết quả&#10;&#10;### Trước khi tối ưu:&#10;- ❌ Gọi 2 lần liên tục → bị chặn 30s&#10;- ❌ Chỉ 5 lần phân tích/ngày&#10;- ❌ Cache không giúp giảm rate limit&#10;&#10;### Sau khi tối ưu:&#10;- ✅ Gọi với cùng CV/JD → **không giới hạn** (cache hit)&#10;- ✅ Gọi với CV/JD khác nhau → chỉ chờ **10s** thay vì 30s&#10;- ✅ **10 lần phân tích mới/ngày** (tăng 2x)&#10;- ✅ Response từ cache &lt; 100ms (rất nhanh)&#10;&#10;##  So sánh Performance&#10;&#10;| Kịch bản | Trước | Sau |&#10;|----------|-------|-----|&#10;| Phân tích cùng CV 2 lần | ❌ Chờ 30s | ✅ Instant (cache) |&#10;| Phân tích CV khác nhau | ⏱️ Chờ 30s | ⏱️ Chờ 10s |&#10;| Quota hàng ngày | 5 lần | 10 lần |&#10;| Response time (cache hit) | N/A | &lt; 100ms |&#10;| Response time (AI call) | ~3-5s | ~3-5s |&#10;&#10;##  Cấu hình nâng cao (Environment Variables)&#10;&#10;Bạn có thể điều chỉnh thông qua file `.env`:&#10;&#10;```bash&#10;# Cache TTL (mặc định: 7 ngày)&#10;AI_CV_ANALYSIS_CACHE_TTL=604800&#10;&#10;# Cache version (thay đổi để invalidate cache cũ)&#10;AI_CV_ANALYSIS_CACHE_VERSION=v1&#10;&#10;# FREE plan limits&#10;AI_CV_FREE_DAILY=10&#10;AI_CV_FREE_INTERVAL=10&#10;&#10;# PRO plan limits&#10;AI_CV_PRO_DAILY=200&#10;AI_CV_PRO_INTERVAL=5&#10;&#10;# ENTERPRISE plan limits&#10;AI_CV_ENT_DAILY=1000&#10;AI_CV_ENT_INTERVAL=1&#10;```&#10;&#10;##  Debugging&#10;&#10;### Kiểm tra cache directory:&#10;```bash&#10;dir &quot;D:\FPT_Uni\Fall 2025\be-python\.cache\ai_cv_analysis&quot;&#10;```&#10;&#10;### Xóa cache nếu cần:&#10;```bash&#10;rmdir /s /q &quot;D:\FPT_Uni\Fall 2025\be-python\.cache\ai_cv_analysis&quot;&#10;```&#10;&#10;### Kiểm tra Redis throttle keys:&#10;```bash&#10;redis-cli&#10;&gt; KEYS rl:cv:*&#10;&gt; TTL rl:cv:free:127.0.0.1:throttle&#10;```&#10;&#10;##  Best Practices cho người dùng&#10;&#10;1. **Test với cùng CV nhiều lần?** → Cache sẽ xử lý, không lo rate limit&#10;2. **Muốn thử với JD khác nhau?** → Đợi 10s giữa các request&#10;3. **Cần kết quả mới nhất?** → Thêm `force_refresh=true`&#10;4. **Hết quota?** → Chờ đến 00:00 hoặc nâng cấp lên PRO plan&#10;&#10;##  Files đã sửa đổi&#10;1. ✅ `apps/recommendation_agent/services/overlap_skill.py` (fix syntax error)&#10;2. ✅ `apps/cv_analysis_agent/utils/rate_limit.py` (giảm interval, tăng quota)&#10;3. ✅ `apps/cv_analysis_agent/view/resume_analysis_view.py` (cache-first strategy)&#10;4. ✅ `apps/cv_analysis_agent/services/ai_checker_resume_service.py` (add try_get_cached_result)&#10;&#10;---&#10;**Updated**: November 29, 2025&#10;**Status**: ✅ Ready for production&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/apps/cv_analysis_agent/services/ai_checker_resume_service.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/apps/cv_analysis_agent/services/ai_checker_resume_service.py" />
              <option name="originalContent" value="import os&#10;import json&#10;import hashlib&#10;import time&#10;from agent_core.llm import get_openai_model&#10;from . import clean_json_output, extract_text&#10;&#10;&#10;&#10;#  Fixed explanations for each section (like Cake.me)&#10;FIELD_EXPLANATIONS = {&#10;    &quot;content&quot;: (&#10;        &quot;This section ensures your resume includes clearly quantifiable results &quot;&#10;        &quot;and is free of grammatical or spelling errors. These improvements make your resume &quot;&#10;        &quot;more impressive and memorable to recruiters.&quot;&#10;    ),&#10;    &quot;skills&quot;: (&#10;        &quot;This section compares your resume against the job description to identify missing or &quot;&#10;        &quot;underrepresented skills. Adding these skills increases the chance of passing ATS filters.&quot;&#10;    ),&#10;    &quot;format&quot;: (&#10;        &quot;This section checks date formats, resume length, and the effective use of bullet points &quot;&#10;        &quot;to ensure your resume is clean, concise, and ATS-friendly.&quot;&#10;    ),&#10;    &quot;sections&quot;: (&#10;        &quot;This section checks whether all required fields — such as contact information and &quot;&#10;        &quot;work experience — are properly filled and formatted, ensuring ATS compatibility.&quot;&#10;    ),&#10;    &quot;style&quot;: (&#10;        &quot;This section helps adjust the tone and wording of your resume to align with the job &quot;&#10;        &quot;description while avoiding generic or cliché phrases, resulting in a more professional and impactful resume.&quot;&#10;    ),&#10;}&#10;&#10;#  Footer section — personalized improvement recommendations&#10;RECOMMENDATION_HEADER = {&#10;    &quot;title&quot;: &quot;Recommendations for You&quot;,&#10;    &quot;description&quot;: (&#10;        &quot;Here are some personalized recommendations to help you improve your resume and &quot;&#10;        &quot;increase your ATS score, as well as suggestions to guide your skill or career development.&quot;&#10;    ),&#10;}&#10;&#10;CACHE_DIR = os.path.join(os.path.dirname(__file__), &quot;../../../.cache/ai_cv_analysis&quot;)&#10;CACHE_TTL_SECONDS = int(os.getenv(&quot;AI_CV_ANALYSIS_CACHE_TTL&quot;, &quot;604800&quot;))  # 7 days default&#10;CACHE_VERSION = os.getenv(&quot;AI_CV_ANALYSIS_CACHE_VERSION&quot;, &quot;v1&quot;)&#10;&#10;&#10;def _ensure_cache_dir():&#10;    os.makedirs(os.path.abspath(CACHE_DIR), exist_ok=True)&#10;&#10;&#10;def _cache_path(key: str) -&gt; str:&#10;    _ensure_cache_dir()&#10;    return os.path.abspath(os.path.join(CACHE_DIR, f&quot;{key}.json&quot;))&#10;&#10;&#10;def _cache_get(key: str):&#10;    try:&#10;        path = _cache_path(key)&#10;        if not os.path.exists(path):&#10;            return None&#10;        # TTL check&#10;        if CACHE_TTL_SECONDS &gt; 0:&#10;            mtime = os.path.getmtime(path)&#10;            if time.time() - mtime &gt; CACHE_TTL_SECONDS:&#10;                return None&#10;        with open(path, &quot;r&quot;, encoding=&quot;utf-8&quot;) as f:&#10;            data = json.load(f)&#10;        # mark cache hit&#10;        if isinstance(data, dict):&#10;            data.setdefault(&quot;cache&quot;, {})&#10;            data[&quot;cache&quot;].update({&quot;hit&quot;: True, &quot;key&quot;: key, &quot;age_seconds&quot;: int(time.time() - os.path.getmtime(path))})&#10;        return data&#10;    except Exception:&#10;        return None&#10;&#10;&#10;def _cache_set(key: str, result: dict):&#10;    path = _cache_path(key)&#10;    tmp = path + &quot;.tmp&quot;&#10;    # include cache metadata&#10;    to_write = dict(result)&#10;    to_write.setdefault(&quot;cache&quot;, {})&#10;    to_write[&quot;cache&quot;].update({&quot;hit&quot;: False, &quot;key&quot;: key, &quot;stored_at&quot;: int(time.time())})&#10;    with open(tmp, &quot;w&quot;, encoding=&quot;utf-8&quot;) as f:&#10;        json.dump(to_write, f, ensure_ascii=False)&#10;    os.replace(tmp, path)&#10;&#10;&#10;def analyze_cv_vs_jd(cv_file, job_description: str, force_refresh: bool = False):&#10;    &quot;&quot;&quot;&#10;    AI-powered CV + JD analysis (Cake.me style)&#10;    Returns structured JSON with sections:&#10;    summary, content, skills, format, sections, style, recommendations, overall_score&#10;    &quot;&quot;&quot;&#10;&#10;    # 1️⃣ Extract and normalize CV text&#10;    cv_text = extract_text.extract_text(cv_file)&#10;&#10;    # 2️⃣ Tóm tắt CV và JD để giảm token&#10;    cv_summary = cv_text[:2000]&#10;    jd_summary = job_description[:1500]&#10;&#10;    # 3️⃣ Build the analysis prompt - Tối ưu cho OpenAI&#10;    prompt = f&quot;&quot;&quot;Analyze CV vs Job. Score 0-100. Return ONLY valid JSON.&#10;&#10;{{&#10;  &quot;summary&quot;: {{&quot;overall_match&quot;: &lt;int&gt;, &quot;overview_comment&quot;: &quot;&lt;text&gt;&quot;, &quot;strengths&quot;: [&quot;item1&quot;, &quot;item2&quot;, &quot;item3&quot;], &quot;improvements&quot;: [&quot;item1&quot;, &quot;item2&quot;, &quot;item3&quot;]}},&#10;  &quot;content&quot;: {{&quot;score&quot;: &lt;int&gt;, &quot;measurable_results&quot;: [&quot;item1&quot;, &quot;item2&quot;], &quot;grammar_issues&quot;: [&quot;item1&quot;, &quot;item2&quot;], &quot;tips&quot;: [&quot;item1&quot;, &quot;item2&quot;]}},&#10;  &quot;skills&quot;: {{&quot;score&quot;: &lt;int&gt;, &quot;technical&quot;: {{&quot;matched&quot;: [&quot;skill1&quot;, &quot;skill2&quot;, &quot;skill3&quot;], &quot;missing&quot;: [&quot;skill1&quot;, &quot;skill2&quot;, &quot;skill3&quot;]}}, &quot;soft&quot;: {{&quot;missing&quot;: [&quot;skill1&quot;, &quot;skill2&quot;]}}, &quot;tips&quot;: [&quot;item1&quot;, &quot;item2&quot;]}},&#10;  &quot;format&quot;: {{&quot;score&quot;: &lt;int&gt;, &quot;checks&quot;: {{&quot;date_format&quot;: &quot;PASS|FAIL&quot;, &quot;length&quot;: &quot;PASS|FAIL&quot;, &quot;bullet_points&quot;: &quot;PASS|FAIL&quot;}}, &quot;tips&quot;: [&quot;item1&quot;, &quot;item2&quot;]}},&#10;  &quot;sections&quot;: {{&quot;score&quot;: &lt;int&gt;, &quot;missing&quot;: [&quot;section1&quot;, &quot;section2&quot;], &quot;tips&quot;: [&quot;item1&quot;, &quot;item2&quot;]}},&#10;  &quot;style&quot;: {{&quot;score&quot;: &lt;int&gt;, &quot;tone&quot;: [&quot;issue1&quot;, &quot;issue2&quot;], &quot;buzzwords&quot;: [&quot;word1&quot;, &quot;word2&quot;], &quot;tips&quot;: [&quot;item1&quot;, &quot;item2&quot;]}},&#10;  &quot;recommendations&quot;: {{&quot;items&quot;: [&quot;rec1&quot;, &quot;rec2&quot;, &quot;rec3&quot;]}},&#10;  &quot;overall_score&quot;: &lt;int&gt;,&#10;  &quot;overall_comment&quot;: &quot;&lt;text max 50 words&gt;&quot;&#10;}}&#10;&#10;RESUME:&#10;{cv_summary}&#10;&#10;JOB DESCRIPTION:&#10;{jd_summary}&#10;&#10;Analyze and return complete JSON:&quot;&quot;&quot;&#10;&#10;    # 3.5️⃣ Cache key by full prompt hash + config (prompt caching)&#10;    # Include cache version, model/config to avoid stale collisions after changes&#10;    model_config = {&#10;        &quot;model&quot;: os.getenv(&quot;OPENAI_MODEL&quot;, &quot;gpt-4o-mini&quot;),&#10;        &quot;temperature&quot;: 0.5,&#10;        &quot;top_p&quot;: 0.9,&#10;    }&#10;    key_basis = json.dumps({&#10;        &quot;version&quot;: CACHE_VERSION,&#10;        &quot;prompt&quot;: prompt,&#10;        &quot;config&quot;: model_config,&#10;    }, ensure_ascii=False)&#10;    key = hashlib.sha256(key_basis.encode(&quot;utf-8&quot;)).hexdigest()&#10;&#10;    if not force_refresh:&#10;        cached = _cache_get(key)&#10;        if cached:&#10;            print(f&quot;️ Cache HIT: {key} (age={cached.get('cache',{}).get('age_seconds','?')}s)&quot;)&#10;            return cached&#10;    else:&#10;        print(&quot;️ Cache BYPASSED (force_refresh=True)&quot;)&#10;&#10;    # 4️⃣ Run OpenAI API&#10;    model = get_openai_model(temperature=model_config[&quot;temperature&quot;], top_p=model_config[&quot;top_p&quot;])&#10;&#10;    try:&#10;        # Gọi OpenAI invoke() thay vì generate_content()&#10;        response = model.invoke(prompt)&#10;        raw_text = response.content if hasattr(response, 'content') else str(response)&#10;        raw_text = raw_text.strip()&#10;&#10;        # OpenAI không có usage_metadata như Gemini&#10;        # Tính token ước tính (OpenAI ~4 chars = 1 token)&#10;        input_tokens = len(prompt) // 4&#10;        output_tokens = len(raw_text) // 4&#10;        total_tokens = input_tokens + output_tokens&#10;&#10;        print(f&quot; Input tokens (estimated): {input_tokens}&quot;)&#10;        print(f&quot; Output tokens (estimated): {output_tokens}&quot;)&#10;        print(f&quot; Total tokens (estimated): {total_tokens}&quot;)&#10;&#10;    except Exception as e:&#10;        print(f&quot;❌ OpenAI Error: {str(e)}&quot;)&#10;&#10;        # Fallback JSON nếu lỗi&#10;        raw_text = json.dumps({&#10;            &quot;summary&quot;: {&#10;                &quot;overall_match&quot;: 50,&#10;                &quot;overview_comment&quot;: &quot;Analysis incomplete&quot;,&#10;                &quot;strengths&quot;: [&quot;Resume submitted&quot;],&#10;                &quot;improvements&quot;: [&quot;Please try again&quot;]&#10;            },&#10;            &quot;content&quot;: {&quot;score&quot;: 50, &quot;measurable_results&quot;: [], &quot;grammar_issues&quot;: [], &quot;tips&quot;: []},&#10;            &quot;skills&quot;: {&quot;score&quot;: 50, &quot;technical&quot;: {&quot;matched&quot;: [], &quot;missing&quot;: []}, &quot;soft&quot;: {&quot;missing&quot;: []}, &quot;tips&quot;: []},&#10;            &quot;format&quot;: {&quot;score&quot;: 50, &quot;checks&quot;: {&quot;date_format&quot;: &quot;PASS&quot;, &quot;length&quot;: &quot;PASS&quot;, &quot;bullet_points&quot;: &quot;PASS&quot;}, &quot;tips&quot;: []},&#10;            &quot;sections&quot;: {&quot;score&quot;: 50, &quot;missing&quot;: [], &quot;tips&quot;: []},&#10;            &quot;style&quot;: {&quot;score&quot;: 50, &quot;tone&quot;: [], &quot;buzzwords&quot;: [], &quot;tips&quot;: []},&#10;            &quot;recommendations&quot;: {&quot;items&quot;: [&quot;Please retry&quot;]},&#10;            &quot;overall_score&quot;: 50,&#10;            &quot;overall_comment&quot;: &quot;Error occurred&quot;&#10;        })&#10;&#10;        input_tokens = len(prompt) // 4&#10;        output_tokens = len(raw_text) // 4&#10;        total_tokens = input_tokens + output_tokens&#10;&#10;    # 5️⃣ Clean and parse the JSON safely&#10;    result = clean_json_output.clean_json_output(raw_text)&#10;&#10;    # 6️⃣ Inject static explanations into each ATS field&#10;    for key_field, desc in FIELD_EXPLANATIONS.items():&#10;        if key_field in result:&#10;            result[key_field][&quot;description&quot;] = desc&#10;        else:&#10;            result[key_field] = {&quot;description&quot;: desc}&#10;&#10;    # 7️⃣ Ensure recommendations section exists&#10;    if &quot;recommendations&quot; not in result:&#10;        result[&quot;recommendations&quot;] = {&quot;items&quot;: []}&#10;    result[&quot;recommendations&quot;].update({&#10;        &quot;title&quot;: &quot;Recommendations for You&quot;,&#10;        &quot;description&quot;: (&#10;            &quot;Here are some personalized recommendations to help you improve your resume and &quot;&#10;            &quot;increase your ATS score, as well as suggestions to guide your skill or career development.&quot;&#10;        ),&#10;    })&#10;&#10;    # 8️⃣ Add token usage info to result&#10;    result[&quot;token_usage&quot;] = {&#10;        &quot;input_tokens&quot;: input_tokens,&#10;        &quot;output_tokens&quot;: output_tokens,&#10;        &quot;total_tokens&quot;: total_tokens,&#10;        &quot;estimated&quot;: True,&#10;        &quot;cache&quot;: {&#10;            &quot;key&quot;: key,&#10;            &quot;hit&quot;: False if force_refresh else False,&#10;        },&#10;    }&#10;&#10;    # 9️⃣ Save to cache&#10;    _cache_set(key, result)&#10;&#10;    return result&#10;" />
              <option name="updatedContent" value="import os&#10;import json&#10;import hashlib&#10;import time&#10;from agent_core.llm import get_openai_model&#10;from . import clean_json_output, extract_text&#10;&#10;&#10;&#10;#  Fixed explanations for each section (like Cake.me)&#10;FIELD_EXPLANATIONS = {&#10;    &quot;content&quot;: (&#10;        &quot;This section ensures your resume includes clearly quantifiable results &quot;&#10;        &quot;and is free of grammatical or spelling errors. These improvements make your resume &quot;&#10;        &quot;more impressive and memorable to recruiters.&quot;&#10;    ),&#10;    &quot;skills&quot;: (&#10;        &quot;This section compares your resume against the job description to identify missing or &quot;&#10;        &quot;underrepresented skills. Adding these skills increases the chance of passing ATS filters.&quot;&#10;    ),&#10;    &quot;format&quot;: (&#10;        &quot;This section checks date formats, resume length, and the effective use of bullet points &quot;&#10;        &quot;to ensure your resume is clean, concise, and ATS-friendly.&quot;&#10;    ),&#10;    &quot;sections&quot;: (&#10;        &quot;This section checks whether all required fields — such as contact information and &quot;&#10;        &quot;work experience — are properly filled and formatted, ensuring ATS compatibility.&quot;&#10;    ),&#10;    &quot;style&quot;: (&#10;        &quot;This section helps adjust the tone and wording of your resume to align with the job &quot;&#10;        &quot;description while avoiding generic or cliché phrases, resulting in a more professional and impactful resume.&quot;&#10;    ),&#10;}&#10;&#10;#  Footer section — personalized improvement recommendations&#10;RECOMMENDATION_HEADER = {&#10;    &quot;title&quot;: &quot;Recommendations for You&quot;,&#10;    &quot;description&quot;: (&#10;        &quot;Here are some personalized recommendations to help you improve your resume and &quot;&#10;        &quot;increase your ATS score, as well as suggestions to guide your skill or career development.&quot;&#10;    ),&#10;}&#10;&#10;CACHE_DIR = os.path.join(os.path.dirname(__file__), &quot;../../../.cache/ai_cv_analysis&quot;)&#10;CACHE_TTL_SECONDS = int(os.getenv(&quot;AI_CV_ANALYSIS_CACHE_TTL&quot;, &quot;604800&quot;))  # 7 days default&#10;CACHE_VERSION = os.getenv(&quot;AI_CV_ANALYSIS_CACHE_VERSION&quot;, &quot;v1&quot;)&#10;&#10;&#10;def _ensure_cache_dir():&#10;    os.makedirs(os.path.abspath(CACHE_DIR), exist_ok=True)&#10;&#10;&#10;def _cache_path(key: str) -&gt; str:&#10;    _ensure_cache_dir()&#10;    return os.path.abspath(os.path.join(CACHE_DIR, f&quot;{key}.json&quot;))&#10;&#10;&#10;def _cache_get(key: str):&#10;    try:&#10;        path = _cache_path(key)&#10;        if not os.path.exists(path):&#10;            return None&#10;        # TTL check&#10;        if CACHE_TTL_SECONDS &gt; 0:&#10;            mtime = os.path.getmtime(path)&#10;            if time.time() - mtime &gt; CACHE_TTL_SECONDS:&#10;                return None&#10;        with open(path, &quot;r&quot;, encoding=&quot;utf-8&quot;) as f:&#10;            data = json.load(f)&#10;        # mark cache hit&#10;        if isinstance(data, dict):&#10;            data.setdefault(&quot;cache&quot;, {})&#10;            data[&quot;cache&quot;].update({&quot;hit&quot;: True, &quot;key&quot;: key, &quot;age_seconds&quot;: int(time.time() - os.path.getmtime(path))})&#10;        return data&#10;    except Exception:&#10;        return None&#10;&#10;&#10;def _cache_set(key: str, result: dict):&#10;    path = _cache_path(key)&#10;    tmp = path + &quot;.tmp&quot;&#10;    # include cache metadata&#10;    to_write = dict(result)&#10;    to_write.setdefault(&quot;cache&quot;, {})&#10;    to_write[&quot;cache&quot;].update({&quot;hit&quot;: False, &quot;key&quot;: key, &quot;stored_at&quot;: int(time.time())})&#10;    with open(tmp, &quot;w&quot;, encoding=&quot;utf-8&quot;) as f:&#10;        json.dump(to_write, f, ensure_ascii=False)&#10;    os.replace(tmp, path)&#10;&#10;&#10;def try_get_cached_result(cv_file, job_description: str):&#10;    &quot;&quot;&quot;&#10;    Try to get cached result without calling AI API.&#10;    Returns cached result if found, None otherwise.&#10;    &quot;&quot;&quot;&#10;    try:&#10;        # Extract and normalize CV text&#10;        cv_text = extract_text.extract_text(cv_file)&#10;        cv_summary = cv_text[:2000]&#10;        jd_summary = job_description[:1500]&#10;&#10;        # Build same cache key as analyze_cv_vs_jd&#10;        model_config = {&#10;            &quot;model&quot;: os.getenv(&quot;OPENAI_MODEL&quot;, &quot;gpt-4o-mini&quot;),&#10;            &quot;temperature&quot;: 0.5,&#10;            &quot;top_p&quot;: 0.9,&#10;        }&#10;        &#10;        prompt = f&quot;&quot;&quot;Analyze CV vs Job. Score 0-100. Return ONLY valid JSON.&#10;&#10;{{&#10;  &quot;summary&quot;: {{&quot;overall_match&quot;: &lt;int&gt;, &quot;overview_comment&quot;: &quot;&lt;text&gt;&quot;, &quot;strengths&quot;: [&quot;item1&quot;, &quot;item2&quot;, &quot;item3&quot;], &quot;improvements&quot;: [&quot;item1&quot;, &quot;item2&quot;, &quot;item3&quot;]}},&#10;  &quot;content&quot;: {{&quot;score&quot;: &lt;int&gt;, &quot;measurable_results&quot;: [&quot;item1&quot;, &quot;item2&quot;], &quot;grammar_issues&quot;: [&quot;item1&quot;, &quot;item2&quot;], &quot;tips&quot;: [&quot;item1&quot;, &quot;item2&quot;]}},&#10;  &quot;skills&quot;: {{&quot;score&quot;: &lt;int&gt;, &quot;technical&quot;: {{&quot;matched&quot;: [&quot;skill1&quot;, &quot;skill2&quot;, &quot;skill3&quot;], &quot;missing&quot;: [&quot;skill1&quot;, &quot;skill2&quot;, &quot;skill3&quot;]}}, &quot;soft&quot;: {{&quot;missing&quot;: [&quot;skill1&quot;, &quot;skill2&quot;]}}, &quot;tips&quot;: [&quot;item1&quot;, &quot;item2&quot;]}},&#10;  &quot;format&quot;: {{&quot;score&quot;: &lt;int&gt;, &quot;checks&quot;: {{&quot;date_format&quot;: &quot;PASS|FAIL&quot;, &quot;length&quot;: &quot;PASS|FAIL&quot;, &quot;bullet_points&quot;: &quot;PASS|FAIL&quot;}}, &quot;tips&quot;: [&quot;item1&quot;, &quot;item2&quot;]}},&#10;  &quot;sections&quot;: {{&quot;score&quot;: &lt;int&gt;, &quot;missing&quot;: [&quot;section1&quot;, &quot;section2&quot;], &quot;tips&quot;: [&quot;item1&quot;, &quot;item2&quot;]}},&#10;  &quot;style&quot;: {{&quot;score&quot;: &lt;int&gt;, &quot;tone&quot;: [&quot;issue1&quot;, &quot;issue2&quot;], &quot;buzzwords&quot;: [&quot;word1&quot;, &quot;word2&quot;], &quot;tips&quot;: [&quot;item1&quot;, &quot;item2&quot;]}},&#10;  &quot;recommendations&quot;: {{&quot;items&quot;: [&quot;rec1&quot;, &quot;rec2&quot;, &quot;rec3&quot;]}},&#10;  &quot;overall_score&quot;: &lt;int&gt;,&#10;  &quot;overall_comment&quot;: &quot;&lt;text max 50 words&gt;&quot;&#10;}}&#10;&#10;RESUME:&#10;{cv_summary}&#10;&#10;JOB DESCRIPTION:&#10;{jd_summary}&#10;&#10;Analyze and return complete JSON:&quot;&quot;&quot;&#10;&#10;        key_basis = json.dumps({&#10;            &quot;version&quot;: CACHE_VERSION,&#10;            &quot;prompt&quot;: prompt,&#10;            &quot;config&quot;: model_config,&#10;        }, ensure_ascii=False)&#10;        key = hashlib.sha256(key_basis.encode(&quot;utf-8&quot;)).hexdigest()&#10;&#10;        # Try to get from cache&#10;        return _cache_get(key)&#10;    except Exception as e:&#10;        print(f&quot;⚠️ Cache check error: {e}&quot;)&#10;        return None&#10;&#10;&#10;def analyze_cv_vs_jd(cv_file, job_description: str, force_refresh: bool = False):&#10;    &quot;&quot;&quot;&#10;    AI-powered CV + JD analysis (Cake.me style)&#10;    Returns structured JSON with sections:&#10;    summary, content, skills, format, sections, style, recommendations, overall_score&#10;    &quot;&quot;&quot;&#10;&#10;    # 1️⃣ Extract and normalize CV text&#10;    cv_text = extract_text.extract_text(cv_file)&#10;&#10;    # 2️⃣ Tóm tắt CV và JD để giảm token&#10;    cv_summary = cv_text[:2000]&#10;    jd_summary = job_description[:1500]&#10;&#10;    # 3️⃣ Build the analysis prompt - Tối ưu cho OpenAI&#10;    prompt = f&quot;&quot;&quot;Analyze CV vs Job. Score 0-100. Return ONLY valid JSON.&#10;&#10;{{&#10;  &quot;summary&quot;: {{&quot;overall_match&quot;: &lt;int&gt;, &quot;overview_comment&quot;: &quot;&lt;text&gt;&quot;, &quot;strengths&quot;: [&quot;item1&quot;, &quot;item2&quot;, &quot;item3&quot;], &quot;improvements&quot;: [&quot;item1&quot;, &quot;item2&quot;, &quot;item3&quot;]}},&#10;  &quot;content&quot;: {{&quot;score&quot;: &lt;int&gt;, &quot;measurable_results&quot;: [&quot;item1&quot;, &quot;item2&quot;], &quot;grammar_issues&quot;: [&quot;item1&quot;, &quot;item2&quot;], &quot;tips&quot;: [&quot;item1&quot;, &quot;item2&quot;]}},&#10;  &quot;skills&quot;: {{&quot;score&quot;: &lt;int&gt;, &quot;technical&quot;: {{&quot;matched&quot;: [&quot;skill1&quot;, &quot;skill2&quot;, &quot;skill3&quot;], &quot;missing&quot;: [&quot;skill1&quot;, &quot;skill2&quot;, &quot;skill3&quot;]}}, &quot;soft&quot;: {{&quot;missing&quot;: [&quot;skill1&quot;, &quot;skill2&quot;]}}, &quot;tips&quot;: [&quot;item1&quot;, &quot;item2&quot;]}},&#10;  &quot;format&quot;: {{&quot;score&quot;: &lt;int&gt;, &quot;checks&quot;: {{&quot;date_format&quot;: &quot;PASS|FAIL&quot;, &quot;length&quot;: &quot;PASS|FAIL&quot;, &quot;bullet_points&quot;: &quot;PASS|FAIL&quot;}}, &quot;tips&quot;: [&quot;item1&quot;, &quot;item2&quot;]}},&#10;  &quot;sections&quot;: {{&quot;score&quot;: &lt;int&gt;, &quot;missing&quot;: [&quot;section1&quot;, &quot;section2&quot;], &quot;tips&quot;: [&quot;item1&quot;, &quot;item2&quot;]}},&#10;  &quot;style&quot;: {{&quot;score&quot;: &lt;int&gt;, &quot;tone&quot;: [&quot;issue1&quot;, &quot;issue2&quot;], &quot;buzzwords&quot;: [&quot;word1&quot;, &quot;word2&quot;], &quot;tips&quot;: [&quot;item1&quot;, &quot;item2&quot;]}},&#10;  &quot;recommendations&quot;: {{&quot;items&quot;: [&quot;rec1&quot;, &quot;rec2&quot;, &quot;rec3&quot;]}},&#10;  &quot;overall_score&quot;: &lt;int&gt;,&#10;  &quot;overall_comment&quot;: &quot;&lt;text max 50 words&gt;&quot;&#10;}}&#10;&#10;RESUME:&#10;{cv_summary}&#10;&#10;JOB DESCRIPTION:&#10;{jd_summary}&#10;&#10;Analyze and return complete JSON:&quot;&quot;&quot;&#10;&#10;    # 3.5️⃣ Cache key by full prompt hash + config (prompt caching)&#10;    # Include cache version, model/config to avoid stale collisions after changes&#10;    model_config = {&#10;        &quot;model&quot;: os.getenv(&quot;OPENAI_MODEL&quot;, &quot;gpt-4o-mini&quot;),&#10;        &quot;temperature&quot;: 0.5,&#10;        &quot;top_p&quot;: 0.9,&#10;    }&#10;    key_basis = json.dumps({&#10;        &quot;version&quot;: CACHE_VERSION,&#10;        &quot;prompt&quot;: prompt,&#10;        &quot;config&quot;: model_config,&#10;    }, ensure_ascii=False)&#10;    key = hashlib.sha256(key_basis.encode(&quot;utf-8&quot;)).hexdigest()&#10;&#10;    if not force_refresh:&#10;        cached = _cache_get(key)&#10;        if cached:&#10;            print(f&quot;️ Cache HIT: {key} (age={cached.get('cache',{}).get('age_seconds','?')}s)&quot;)&#10;            return cached&#10;    else:&#10;        print(&quot;️ Cache BYPASSED (force_refresh=True)&quot;)&#10;&#10;    # 4️⃣ Run OpenAI API&#10;    model = get_openai_model(temperature=model_config[&quot;temperature&quot;], top_p=model_config[&quot;top_p&quot;])&#10;&#10;    try:&#10;        # Gọi OpenAI invoke() thay vì generate_content()&#10;        response = model.invoke(prompt)&#10;        raw_text = response.content if hasattr(response, 'content') else str(response)&#10;        raw_text = raw_text.strip()&#10;&#10;        # OpenAI không có usage_metadata như Gemini&#10;        # Tính token ước tính (OpenAI ~4 chars = 1 token)&#10;        input_tokens = len(prompt) // 4&#10;        output_tokens = len(raw_text) // 4&#10;        total_tokens = input_tokens + output_tokens&#10;&#10;        print(f&quot; Input tokens (estimated): {input_tokens}&quot;)&#10;        print(f&quot; Output tokens (estimated): {output_tokens}&quot;)&#10;        print(f&quot; Total tokens (estimated): {total_tokens}&quot;)&#10;&#10;    except Exception as e:&#10;        print(f&quot;❌ OpenAI Error: {str(e)}&quot;)&#10;&#10;        # Fallback JSON nếu lỗi&#10;        raw_text = json.dumps({&#10;            &quot;summary&quot;: {&#10;                &quot;overall_match&quot;: 50,&#10;                &quot;overview_comment&quot;: &quot;Analysis incomplete&quot;,&#10;                &quot;strengths&quot;: [&quot;Resume submitted&quot;],&#10;                &quot;improvements&quot;: [&quot;Please try again&quot;]&#10;            },&#10;            &quot;content&quot;: {&quot;score&quot;: 50, &quot;measurable_results&quot;: [], &quot;grammar_issues&quot;: [], &quot;tips&quot;: []},&#10;            &quot;skills&quot;: {&quot;score&quot;: 50, &quot;technical&quot;: {&quot;matched&quot;: [], &quot;missing&quot;: []}, &quot;soft&quot;: {&quot;missing&quot;: []}, &quot;tips&quot;: []},&#10;            &quot;format&quot;: {&quot;score&quot;: 50, &quot;checks&quot;: {&quot;date_format&quot;: &quot;PASS&quot;, &quot;length&quot;: &quot;PASS&quot;, &quot;bullet_points&quot;: &quot;PASS&quot;}, &quot;tips&quot;: []},&#10;            &quot;sections&quot;: {&quot;score&quot;: 50, &quot;missing&quot;: [], &quot;tips&quot;: []},&#10;            &quot;style&quot;: {&quot;score&quot;: 50, &quot;tone&quot;: [], &quot;buzzwords&quot;: [], &quot;tips&quot;: []},&#10;            &quot;recommendations&quot;: {&quot;items&quot;: [&quot;Please retry&quot;]},&#10;            &quot;overall_score&quot;: 50,&#10;            &quot;overall_comment&quot;: &quot;Error occurred&quot;&#10;        })&#10;&#10;        input_tokens = len(prompt) // 4&#10;        output_tokens = len(raw_text) // 4&#10;        total_tokens = input_tokens + output_tokens&#10;&#10;    # 5️⃣ Clean and parse the JSON safely&#10;    result = clean_json_output.clean_json_output(raw_text)&#10;&#10;    # 6️⃣ Inject static explanations into each ATS field&#10;    for key_field, desc in FIELD_EXPLANATIONS.items():&#10;        if key_field in result:&#10;            result[key_field][&quot;description&quot;] = desc&#10;        else:&#10;            result[key_field] = {&quot;description&quot;: desc}&#10;&#10;    # 7️⃣ Ensure recommendations section exists&#10;    if &quot;recommendations&quot; not in result:&#10;        result[&quot;recommendations&quot;] = {&quot;items&quot;: []}&#10;    result[&quot;recommendations&quot;].update({&#10;        &quot;title&quot;: &quot;Recommendations for You&quot;,&#10;        &quot;description&quot;: (&#10;            &quot;Here are some personalized recommendations to help you improve your resume and &quot;&#10;            &quot;increase your ATS score, as well as suggestions to guide your skill or career development.&quot;&#10;        ),&#10;    })&#10;&#10;    # 8️⃣ Add token usage info to result&#10;    result[&quot;token_usage&quot;] = {&#10;        &quot;input_tokens&quot;: input_tokens,&#10;        &quot;output_tokens&quot;: output_tokens,&#10;        &quot;total_tokens&quot;: total_tokens,&#10;        &quot;estimated&quot;: True,&#10;        &quot;cache&quot;: {&#10;            &quot;key&quot;: key,&#10;            &quot;hit&quot;: False if force_refresh else False,&#10;        },&#10;    }&#10;&#10;    # 9️⃣ Save to cache&#10;    _cache_set(key, result)&#10;&#10;    return result" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/apps/cv_analysis_agent/utils/rate_limit.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/apps/cv_analysis_agent/utils/rate_limit.py" />
              <option name="originalContent" value="import os&#10;import datetime as dt&#10;from typing import Optional, Tuple&#10;&#10;try:&#10;    import redis  # type: ignore&#10;except Exception:  # pragma: no cover&#10;    redis = None  # Fallback if redis not installed at runtime&#10;&#10;from django.conf import settings&#10;from django.utils import timezone&#10;&#10;&#10;def _get_redis_url() -&gt; str:&#10;    return (&#10;        os.getenv(&quot;REDIS_URL&quot;)&#10;        or os.getenv(&quot;CELERY_BROKER_URL&quot;)&#10;        or &quot;redis://localhost:6379/0&quot;&#10;    )&#10;&#10;&#10;def get_redis_client():&#10;    if redis is None:&#10;        return None&#10;    try:&#10;        return redis.Redis.from_url(_get_redis_url(), decode_responses=True)&#10;    except Exception:&#10;        return None&#10;&#10;&#10;def _end_of_day_seconds(now: Optional[dt.datetime] = None) -&gt; int:&#10;    tz = timezone.get_current_timezone()&#10;    now = now or timezone.now()&#10;    now = now.astimezone(tz)&#10;    eod = (now + dt.timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)&#10;    return int((eod - now).total_seconds())&#10;&#10;&#10;def _plan_quota(plan: str) -&gt; Tuple[int, int]:&#10;    plan = (plan or &quot;free&quot;).lower()&#10;    if plan == &quot;pro&quot;:&#10;        return (&#10;            int(os.getenv(&quot;AI_CV_PRO_DAILY&quot;, &quot;200&quot;)),&#10;            int(os.getenv(&quot;AI_CV_PRO_INTERVAL&quot;, &quot;5&quot;)),&#10;        )&#10;    if plan in (&quot;enterprise&quot;, &quot;ent&quot;):  # alias&#10;        return (&#10;            int(os.getenv(&quot;AI_CV_ENT_DAILY&quot;, &quot;1000&quot;)),&#10;            int(os.getenv(&quot;AI_CV_ENT_INTERVAL&quot;, &quot;1&quot;)),&#10;        )&#10;    # default: free&#10;    return (&#10;        int(os.getenv(&quot;AI_CV_FREE_DAILY&quot;, &quot;5&quot;)),&#10;        int(os.getenv(&quot;AI_CV_FREE_INTERVAL&quot;, &quot;30&quot;)),&#10;    )&#10;&#10;&#10;def _user_key_base(user_id: str, plan: str) -&gt; str:&#10;    return f&quot;rl:cv:{plan}:{user_id}&quot;&#10;&#10;&#10;def enforce_rate_limit(user_id: str, plan: str = &quot;free&quot;) -&gt; Tuple[bool, dict]:&#10;    &quot;&quot;&quot;&#10;    Enforce both daily quota and min-interval throttle for a user.&#10;    Returns (allowed: bool, info: dict).&#10;    info contains reason and retry_after on block, or remaining on allow.&#10;    &quot;&quot;&quot;&#10;    r = get_redis_client()&#10;    daily_limit, min_interval = _plan_quota(plan)&#10;    base = _user_key_base(user_id, plan)&#10;&#10;    # If Redis is unavailable, allow request but mark degraded&#10;    if r is None:&#10;        return True, {&#10;            &quot;degraded&quot;: True,&#10;            &quot;message&quot;: &quot;Rate limit backend unavailable; allowing request&quot;,&#10;        }&#10;&#10;    # Throttle: 1 request per min_interval seconds (SETNX with TTL)&#10;    throttle_key = f&quot;{base}:throttle&quot;&#10;    if min_interval &gt; 0:&#10;        set_ok = r.set(throttle_key, &quot;1&quot;, nx=True, ex=min_interval)&#10;        if not set_ok:&#10;            ttl = r.ttl(throttle_key)&#10;            return False, {&#10;                &quot;reason&quot;: &quot;interval&quot;,&#10;                &quot;retry_after&quot;: max(ttl, 1) if ttl and ttl &gt; 0 else min_interval,&#10;                &quot;message&quot;: f&quot;Too many requests. Try again in {max(ttl,1) if ttl else min_interval}s&quot;,&#10;            }&#10;&#10;    # Daily quota: INCR with expiry at end of day&#10;    today = timezone.now().astimezone(timezone.get_current_timezone()).strftime(&quot;%Y%m%d&quot;)&#10;    daily_key = f&quot;{base}:daily:{today}&quot;&#10;    current = r.incr(daily_key, 1)&#10;    # set expiry if new&#10;    if current == 1:&#10;        r.expire(daily_key, _end_of_day_seconds())&#10;&#10;    if current &gt; daily_limit:&#10;        ttl = r.ttl(daily_key)&#10;        return False, {&#10;            &quot;reason&quot;: &quot;daily&quot;,&#10;            &quot;retry_after&quot;: max(ttl, 60) if ttl and ttl &gt; 0 else 3600,&#10;            &quot;message&quot;: &quot;Daily quota exceeded&quot;,&#10;            &quot;limit&quot;: daily_limit,&#10;            &quot;used&quot;: int(current),&#10;            &quot;reset_in&quot;: ttl,&#10;        }&#10;&#10;    return True, {&#10;        &quot;remaining_today&quot;: max(daily_limit - int(current), 0),&#10;        &quot;interval_lock&quot;: min_interval,&#10;    }&#10;&#10;" />
              <option name="updatedContent" value="import os&#13;&#10;import datetime as dt&#13;&#10;from typing import Optional, Tuple&#13;&#10;&#13;&#10;try:&#13;&#10;    import redis  # type: ignore&#13;&#10;except Exception:  # pragma: no cover&#13;&#10;    redis = None  # Fallback if redis not installed at runtime&#13;&#10;&#13;&#10;from django.conf import settings&#13;&#10;from django.utils import timezone&#13;&#10;&#13;&#10;&#13;&#10;def _get_redis_url() -&gt; str:&#13;&#10;    return (&#13;&#10;        os.getenv(&quot;REDIS_URL&quot;)&#13;&#10;        or os.getenv(&quot;CELERY_BROKER_URL&quot;)&#13;&#10;        or &quot;redis://localhost:6379/0&quot;&#13;&#10;    )&#13;&#10;&#13;&#10;&#13;&#10;def get_redis_client():&#13;&#10;    if redis is None:&#13;&#10;        return None&#13;&#10;    try:&#13;&#10;        return redis.Redis.from_url(_get_redis_url(), decode_responses=True)&#13;&#10;    except Exception:&#13;&#10;        return None&#13;&#10;&#13;&#10;&#13;&#10;def _end_of_day_seconds(now: Optional[dt.datetime] = None) -&gt; int:&#13;&#10;    tz = timezone.get_current_timezone()&#13;&#10;    now = now or timezone.now()&#13;&#10;    now = now.astimezone(tz)&#13;&#10;    eod = (now + dt.timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)&#13;&#10;    return int((eod - now).total_seconds())&#13;&#10;&#13;&#10;&#13;&#10;def _plan_quota(plan: str) -&gt; Tuple[int, int]:&#13;&#10;    plan = (plan or &quot;free&quot;).lower()&#13;&#10;    if plan == &quot;pro&quot;:&#13;&#10;        return (&#13;&#10;            int(os.getenv(&quot;AI_CV_PRO_DAILY&quot;, &quot;200&quot;)),&#13;&#10;            int(os.getenv(&quot;AI_CV_PRO_INTERVAL&quot;, &quot;5&quot;)),&#13;&#10;        )&#13;&#10;    if plan in (&quot;enterprise&quot;, &quot;ent&quot;):  # alias&#13;&#10;        return (&#13;&#10;            int(os.getenv(&quot;AI_CV_ENT_DAILY&quot;, &quot;1000&quot;)),&#13;&#10;            int(os.getenv(&quot;AI_CV_ENT_INTERVAL&quot;, &quot;1&quot;)),&#13;&#10;        )&#13;&#10;    # default: free - Giảm từ 30s → 10s để UX tốt hơn&#13;&#10;    # Cache sẽ xử lý việc tránh gọi API nhiều lần&#13;&#10;    return (&#13;&#10;        int(os.getenv(&quot;AI_CV_FREE_DAILY&quot;, &quot;10&quot;)),  # Tăng từ 5 → 10 lần/ngày&#13;&#10;        int(os.getenv(&quot;AI_CV_FREE_INTERVAL&quot;, &quot;10&quot;)),  # Giảm từ 30s → 10s&#13;&#10;    )&#13;&#10;&#13;&#10;&#13;&#10;def _user_key_base(user_id: str, plan: str) -&gt; str:&#13;&#10;    return f&quot;rl:cv:{plan}:{user_id}&quot;&#13;&#10;&#13;&#10;&#13;&#10;def enforce_rate_limit(user_id: str, plan: str = &quot;free&quot;) -&gt; Tuple[bool, dict]:&#13;&#10;    &quot;&quot;&quot;&#13;&#10;    Enforce both daily quota and min-interval throttle for a user.&#13;&#10;    Returns (allowed: bool, info: dict).&#13;&#10;    info contains reason and retry_after on block, or remaining on allow.&#13;&#10;    &quot;&quot;&quot;&#13;&#10;    r = get_redis_client()&#13;&#10;    daily_limit, min_interval = _plan_quota(plan)&#13;&#10;    base = _user_key_base(user_id, plan)&#13;&#10;&#13;&#10;    # If Redis is unavailable, allow request but mark degraded&#13;&#10;    if r is None:&#13;&#10;        return True, {&#13;&#10;            &quot;degraded&quot;: True,&#13;&#10;            &quot;message&quot;: &quot;Rate limit backend unavailable; allowing request&quot;,&#13;&#10;        }&#13;&#10;&#13;&#10;    # Throttle: 1 request per min_interval seconds (SETNX with TTL)&#13;&#10;    throttle_key = f&quot;{base}:throttle&quot;&#13;&#10;    if min_interval &gt; 0:&#13;&#10;        set_ok = r.set(throttle_key, &quot;1&quot;, nx=True, ex=min_interval)&#13;&#10;        if not set_ok:&#13;&#10;            ttl = r.ttl(throttle_key)&#13;&#10;            return False, {&#13;&#10;                &quot;reason&quot;: &quot;interval&quot;,&#13;&#10;                &quot;retry_after&quot;: max(ttl, 1) if ttl and ttl &gt; 0 else min_interval,&#13;&#10;                &quot;message&quot;: f&quot;Too many requests. Try again in {max(ttl,1) if ttl else min_interval}s&quot;,&#13;&#10;            }&#13;&#10;&#13;&#10;    # Daily quota: INCR with expiry at end of day&#13;&#10;    today = timezone.now().astimezone(timezone.get_current_timezone()).strftime(&quot;%Y%m%d&quot;)&#13;&#10;    daily_key = f&quot;{base}:daily:{today}&quot;&#13;&#10;    current = r.incr(daily_key, 1)&#13;&#10;    # set expiry if new&#13;&#10;    if current == 1:&#13;&#10;        r.expire(daily_key, _end_of_day_seconds())&#13;&#10;&#13;&#10;    if current &gt; daily_limit:&#13;&#10;        ttl = r.ttl(daily_key)&#13;&#10;        return False, {&#13;&#10;            &quot;reason&quot;: &quot;daily&quot;,&#13;&#10;            &quot;retry_after&quot;: max(ttl, 60) if ttl and ttl &gt; 0 else 3600,&#13;&#10;            &quot;message&quot;: &quot;Daily quota exceeded&quot;,&#13;&#10;            &quot;limit&quot;: daily_limit,&#13;&#10;            &quot;used&quot;: int(current),&#13;&#10;            &quot;reset_in&quot;: ttl,&#13;&#10;        }&#13;&#10;&#13;&#10;    return True, {&#13;&#10;        &quot;remaining_today&quot;: max(daily_limit - int(current), 0),&#13;&#10;        &quot;interval_lock&quot;: min_interval,&#13;&#10;    }" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/apps/cv_analysis_agent/view/resume_analysis_view.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/apps/cv_analysis_agent/view/resume_analysis_view.py" />
              <option name="originalContent" value="from drf_spectacular.utils import extend_schema, OpenApiResponse, OpenApiExample&#10;from rest_framework.permissions import AllowAny&#10;from rest_framework.views import APIView&#10;from rest_framework.parsers import MultiPartParser&#10;from rest_framework.response import Response&#10;from rest_framework import status&#10;from django.utils import timezone&#10;&#10;from ..serializers import ResumeAnalysisSerializer&#10;from ..services import ai_checker_resume_service&#10;from ..utils.rate_limit import enforce_rate_limit&#10;&#10;@extend_schema(&#10;    tags=[&quot;CV Analysis&quot;],&#10;    summary=&quot;Analyze CV/Resume (Async)&quot;,&#10;    description=&quot;Upload a CV/Resume file and description for asynchronous analysis. Returns a task_id to check status &quot;&#10;                &quot;later.&quot;,&#10;    request=ResumeAnalysisSerializer,&#10;    responses={&#10;        202: OpenApiResponse(&#10;            response={&quot;type&quot;: &quot;object&quot;},&#10;            description=&quot;Task created successfully&quot;,&#10;            examples=[&#10;                OpenApiExample(&#10;                    &quot;Success&quot;,&#10;                    value={&#10;                        &quot;task_id&quot;: &quot;a1b2c3d4-5678-90ef-ghij-klmnopqrstuv&quot;,&#10;                        &quot;status&quot;: &quot;processing&quot;&#10;                    }&#10;                )&#10;            ]&#10;        ),&#10;    }&#10;)&#10;class ResumeAtsAnalyzeView(APIView):&#10;    permission_classes = [AllowAny]&#10;    parser_classes = [MultiPartParser]&#10;&#10;    def _get_user_identity_and_plan(self, request):&#10;        # Identify user: prefer authenticated JWT subject, else IP-based fallback&#10;        if getattr(request, 'user', None) and getattr(request.user, 'is_authenticated', False):&#10;            user_id = str(getattr(request.user, 'identifier', 'anonymous'))&#10;        else:&#10;            # Basic IP fallback (not perfect behind proxies)&#10;            user_id = request.META.get('HTTP_X_FORWARDED_FOR', request.META.get('REMOTE_ADDR', 'anonymous'))&#10;        plan = (request.headers.get('X-Plan') or request.query_params.get('plan') or 'free').lower()&#10;        return user_id, plan&#10;&#10;    def post(self, request):&#10;        # Enforce rate limit BEFORE heavy work&#10;        user_id, plan = self._get_user_identity_and_plan(request)&#10;        allowed, info = enforce_rate_limit(user_id=user_id, plan=plan)&#10;        if not allowed:&#10;            return Response({&#10;                &quot;detail&quot;: info.get(&quot;message&quot;) or &quot;Rate limit exceeded&quot;,&#10;                &quot;reason&quot;: info.get(&quot;reason&quot;),&#10;                &quot;retry_after&quot;: info.get(&quot;retry_after&quot;),&#10;                &quot;plan&quot;: plan,&#10;                &quot;user&quot;: user_id,&#10;            }, status=status.HTTP_429_TOO_MANY_REQUESTS)&#10;&#10;        s = ResumeAnalysisSerializer(data=request.data)&#10;        s.is_valid(raise_exception=True)&#10;        jd = s.validated_data.get(&quot;job_description&quot;, &quot;&quot;)&#10;        cv = s.validated_data[&quot;cv_file&quot;]&#10;&#10;        result = ai_checker_resume_service.analyze_cv_vs_jd(cv, jd)&#10;        # Attach rate-limit meta for transparency&#10;        result.setdefault(&quot;rate_limit&quot;, {}).update({&#10;            &quot;plan&quot;: plan,&#10;            &quot;user&quot;: user_id,&#10;            **({k: v for k, v in info.items() if k in (&quot;remaining_today&quot;, &quot;interval_lock&quot;)}),&#10;        })&#10;        return Response(result)&#10;" />
              <option name="updatedContent" value="from drf_spectacular.utils import extend_schema, OpenApiResponse, OpenApiExample&#10;from rest_framework.permissions import AllowAny&#10;from rest_framework.views import APIView&#10;from rest_framework.parsers import MultiPartParser&#10;from rest_framework.response import Response&#10;from rest_framework import status&#10;from django.utils import timezone&#10;&#10;from ..serializers import ResumeAnalysisSerializer&#10;from ..services import ai_checker_resume_service&#10;from ..utils.rate_limit import enforce_rate_limit&#10;&#10;@extend_schema(&#10;    tags=[&quot;CV Analysis&quot;],&#10;    summary=&quot;Analyze CV/Resume (Async)&quot;,&#10;    description=&quot;Upload a CV/Resume file and description for asynchronous analysis. Returns a task_id to check status &quot;&#10;                &quot;later.&quot;,&#10;    request=ResumeAnalysisSerializer,&#10;    responses={&#10;        202: OpenApiResponse(&#10;            response={&quot;type&quot;: &quot;object&quot;},&#10;            description=&quot;Task created successfully&quot;,&#10;            examples=[&#10;                OpenApiExample(&#10;                    &quot;Success&quot;,&#10;                    value={&#10;                        &quot;task_id&quot;: &quot;a1b2c3d4-5678-90ef-ghij-klmnopqrstuv&quot;,&#10;                        &quot;status&quot;: &quot;processing&quot;&#10;                    }&#10;                )&#10;            ]&#10;        ),&#10;    }&#10;)&#10;class ResumeAtsAnalyzeView(APIView):&#10;    permission_classes = [AllowAny]&#10;    parser_classes = [MultiPartParser]&#10;&#10;    def _get_user_identity_and_plan(self, request):&#10;        # Identify user: prefer authenticated JWT subject, else IP-based fallback&#10;        if getattr(request, 'user', None) and getattr(request.user, 'is_authenticated', False):&#10;            user_id = str(getattr(request.user, 'identifier', 'anonymous'))&#10;        else:&#10;            # Basic IP fallback (not perfect behind proxies)&#10;            user_id = request.META.get('HTTP_X_FORWARDED_FOR', request.META.get('REMOTE_ADDR', 'anonymous'))&#10;        plan = (request.headers.get('X-Plan') or request.query_params.get('plan') or 'free').lower()&#10;        return user_id, plan&#10;&#10;    def post(self, request):&#10;        user_id, plan = self._get_user_identity_and_plan(request)&#10;        &#10;        # Check if force_refresh is requested (bypass cache)&#10;        force_refresh = request.data.get('force_refresh', 'false').lower() == 'true'&#10;        &#10;        # Parse request early to check cache BEFORE rate limiting&#10;        s = ResumeAnalysisSerializer(data=request.data)&#10;        s.is_valid(raise_exception=True)&#10;        jd = s.validated_data.get(&quot;job_description&quot;, &quot;&quot;)&#10;        cv = s.validated_data[&quot;cv_file&quot;]&#10;&#10;        # Try cache first (if not force_refresh) - doesn't count against rate limit&#10;        if not force_refresh:&#10;            cached_result = ai_checker_resume_service.try_get_cached_result(cv, jd)&#10;            if cached_result:&#10;                # Cache HIT - return immediately without consuming rate limit&#10;                cached_result.setdefault(&quot;rate_limit&quot;, {}).update({&#10;                    &quot;plan&quot;: plan,&#10;                    &quot;user&quot;: user_id,&#10;                    &quot;cached&quot;: True,&#10;                    &quot;quota_used&quot;: False,&#10;                    &quot;tip&quot;: &quot;This result was served from cache and did not consume your quota.&quot;&#10;                })&#10;                return Response(cached_result)&#10;        &#10;        # Cache MISS or force_refresh - enforce rate limit&#10;        allowed, info = enforce_rate_limit(user_id=user_id, plan=plan)&#10;        if not allowed:&#10;            return Response({&#10;                &quot;detail&quot;: info.get(&quot;message&quot;) or &quot;Rate limit exceeded&quot;,&#10;                &quot;reason&quot;: info.get(&quot;reason&quot;),&#10;                &quot;retry_after&quot;: info.get(&quot;retry_after&quot;),&#10;                &quot;plan&quot;: plan,&#10;                &quot;user&quot;: user_id,&#10;                &quot;tip&quot;: &quot;If you're analyzing the same CV and job description, the cached result will be returned instantly without consuming your quota.&quot;&#10;            }, status=status.HTTP_429_TOO_MANY_REQUESTS)&#10;&#10;        # Pass force_refresh to service&#10;        result = ai_checker_resume_service.analyze_cv_vs_jd(cv, jd, force_refresh=force_refresh)&#10;        &#10;        # Attach rate-limit meta for transparency&#10;        result.setdefault(&quot;rate_limit&quot;, {}).update({&#10;            &quot;plan&quot;: plan,&#10;            &quot;user&quot;: user_id,&#10;            &quot;cached&quot;: False,&#10;            &quot;quota_used&quot;: True,&#10;            **({k: v for k, v in info.items() if k in (&quot;remaining_today&quot;, &quot;interval_lock&quot;)}),&#10;        })&#10;        return Response(result)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/apps/recommendation_agent/services/job_service.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/apps/recommendation_agent/services/job_service.py" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;Job Indexing Service for syncing jobs to Weaviate&#10;&quot;&quot;&quot;&#10;import logging&#10;&#10;logger = logging.getLogger(__name__)&#10;&#10;&#10;class JobIndexingService:&#10;    &quot;&quot;&quot;Service for indexing jobs to Weaviate&quot;&quot;&quot;&#10;    &#10;    @staticmethod&#10;    def sync_single_job_to_weaviate(job_id):&#10;        &quot;&quot;&quot;&#10;        Sync a single job to Weaviate&#10;        &#10;        Args:&#10;            job_id: ID of the job to sync&#10;            &#10;        Returns:&#10;            bool: True if successful, False otherwise&#10;        &quot;&quot;&quot;&#10;        try:&#10;            from ..models import JobPostings, JobDescription&#10;            from .weaviate_service import index_job, delete_job&#10;            &#10;            # Get job from database&#10;            try:&#10;                job = JobPostings.objects.select_related('recruiter').prefetch_related(&#10;                    'jobdescription_set__jd_skill'&#10;                ).get(id=job_id)&#10;            except JobPostings.DoesNotExist:&#10;                logger.warning(f&quot;Job {job_id} not found in database&quot;)&#10;                return False&#10;            &#10;            # If job is not active, remove from Weaviate&#10;            if job.status != 'ACTIVE':&#10;                return delete_job(job_id)&#10;            &#10;            # Prepare job data for indexing&#10;            skills = [jd.jd_skill.name for jd in job.jobdescription_set.all()]&#10;            &#10;            job_data = {&#10;                'job_id': job.id,&#10;                'title': job.title,&#10;                'description': job.description or '',&#10;                'skills': skills,&#10;                'company_name': job.recruiter.company_name,&#10;                'address': job.address or '',&#10;            }&#10;            &#10;            # Index to Weaviate&#10;            return index_job(job_data)&#10;            &#10;        except Exception as e:&#10;            logger.error(f&quot;Error syncing job {job_id} to Weaviate: {str(e)}&quot;)&#10;            return False&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>